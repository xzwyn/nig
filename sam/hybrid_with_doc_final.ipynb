{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a67ddf6-ca9c-4ebf-a687-ab8fb3c8f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "Loading local GGUF model for Reviser/Critic: C:\\Users\\sripa\\Downloads\\Meta-Llama-3.1-8B-Instruct.i1-Q5_K_M.gguf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (8192) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviser/Critic LLM (Llama-3.1) loaded successfully.\n",
      "Loading specialist translation model: LinguaCustodia/FinTranslate-410M\n",
      "Specialist Translation Model (FinTranslate) loaded successfully on cpu.\n",
      "Graph state defined.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PART 1: SYSTEM SETUP (LAYOUT-AWARE)\n",
    "# ==============================================================================\n",
    "\n",
    "# ... (All imports and configuration are the same) ...\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import torch\n",
    "import threading\n",
    "from typing import List, TypedDict, Optional, Dict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from llama_cpp import Llama\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from bs4 import BeautifulSoup\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "# We need more from docx for advanced table/column layout\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "# ... (Configuration, Model Loading, Helper Functions, Glossary, ContextManager, and State are all the same) ...\n",
    "# NOTE: No changes are needed in sections 2, 3, 4, or 5 of the previous code.\n",
    "# The core components are already correct. The only change is how we use them.\n",
    "# For brevity, I am omitting the unchanged sections. They should be copied from the previous final version.\n",
    "# ==============================================================================\n",
    "# 2. CONFIGURATION (WITH MEMORY FIXES)\n",
    "# ==============================================================================\n",
    "# --- File and Processing Configuration ---\n",
    "ENGLISH_PDF_PATH = r\"C:\\Users\\sripa\\Downloads\\Annual Report 2024 Allianz Groupeng.pdf\"\n",
    "\n",
    "# --- MEMORY-SAVING FIXES ARE HERE ---\n",
    "MAX_ELEMENTS_TO_PROCESS = 15 # <<< FIX #1: Process a smaller batch first to ensure success.\n",
    "NUM_WORKERS = 1              # <<< FIX #2: The most important change. Process one element at a time to prevent memory overload.\n",
    "\n",
    "# --- Model Paths & Names ---\n",
    "REVISER_LLM_PATH = r\"C:\\Users\\sripa\\Downloads\\Meta-Llama-3.1-8B-Instruct.i1-Q5_K_M.gguf\"\n",
    "TRANSLATOR_MODEL_NAME = \"LinguaCustodia/FinTranslate-410M\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. HYBRID MODEL LOADING\n",
    "# ==============================================================================\n",
    "print(f\"Loading local GGUF model for Reviser/Critic: {REVISER_LLM_PATH}\")\n",
    "try:\n",
    "    reviser_llm = Llama(model_path=REVISER_LLM_PATH, n_gpu_layers=0, n_ctx=8192, verbose=False, chat_format=\"llama-3\")\n",
    "    print(\"Reviser/Critic LLM (Llama-3.1) loaded successfully.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load local GGUF model: {e}\")\n",
    "\n",
    "print(f\"Loading specialist translation model: {TRANSLATOR_MODEL_NAME}\")\n",
    "try:\n",
    "    fin_tokenizer = AutoTokenizer.from_pretrained(TRANSLATOR_MODEL_NAME)\n",
    "    fin_translator_model = AutoModelForCausalLM.from_pretrained(TRANSLATOR_MODEL_NAME)\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    fin_translator_model.to(DEVICE)\n",
    "    fin_translator_model.eval()\n",
    "    print(f\"Specialist Translation Model (FinTranslate) loaded successfully on {DEVICE}.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load translation model from Hugging Face: {e}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. LINGUACUSTODIA HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "LANGUAGES = [\"en\", \"de\", \"es\", \"fr\", \"it\", \"nl\", \"sv\", \"pt\"]\n",
    "DOMAINS = {\"Annual report\": \"ar\", \"General\": \"general\"}\n",
    "\n",
    "def format_input_for_translator(src: str, tgt_lang: str = \"de\", src_lang: str = \"en\", domain: str = \"Annual report\") -> str:\n",
    "    domain_code = DOMAINS.get(domain, \"general\")\n",
    "    return f\"<eos>{src}</src><lang_{tgt_lang}><lang_{src_lang}><dom_{domain_code}>\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. GLOSSARY, STATE, AND FULLY-FEATURED CONTEXT MANAGER\n",
    "# ==============================================================================\n",
    "FINANCIAL_GLOSSARY = {\n",
    "    \"Actions\": \"MaÃŸnahmen\", \"Annual Report\": \"GeschÃ¤ftsbericht\", \"Asset managers\": \"VermÃ¶gensverwalter\",\n",
    "    \"Balance Sheet\": \"Bilanz\", \"Basis for preparation\": \"Grundlagen fÃ¼r die Erstellung\",\n",
    "    \"Board of Management\": \"Vorstand\", \"Climate change\": \"Klimawandel\",\n",
    "    \"Consolidated financial statements\": \"Konzernabschluss\", \"Financial year\": \"GeschÃ¤ftsjahr\",\n",
    "    \"Revenue\": \"Umsatz\", \"Sustainability Statement\": \"NachhaltigkeitserklÃ¤rung\"\n",
    "}\n",
    "\n",
    "def format_number_de(text: str) -> str:\n",
    "    return re.sub(r'(\\d{1,3}(?:,\\d{3})*(\\.\\d+)?)|(\\d+)',\n",
    "                  lambda m: m.group(0).replace(',', 'X').replace('.', ',').replace('X', '.'),\n",
    "                  text)\n",
    "\n",
    "def extract_text_from_html(html: str) -> str:\n",
    "    if not html: return \"\"\n",
    "    return \" \".join(BeautifulSoup(html, \"lxml\").get_text().split())\n",
    "def extract_text_from_html(html: str) -> str:\n",
    "    if not html: return \"\"\n",
    "    return \" \".join(BeautifulSoup(html, \"lxml\").get_text().split())\n",
    "\n",
    "class DocumentContextManager:\n",
    "    def __init__(self):\n",
    "        self.term_decisions = {}\n",
    "        # The lock is still good practice even with one worker, in case it's increased later\n",
    "        self.lock = threading.Lock()\n",
    "        print(\"Thread-safe Document Context Manager initialized.\")\n",
    "    def register_decision(self, en_term: str, de_term: str):\n",
    "        with self.lock:\n",
    "            en_term_lower = en_term.lower()\n",
    "            if en_term_lower not in self.term_decisions:\n",
    "                self.term_decisions[en_term_lower] = de_term\n",
    "                print(f\"CONTEXT MGR: Registered '{en_term}' -> '{de_term}'\")\n",
    "    def get_decision(self, en_term: str) -> Optional[str]:\n",
    "        with self.lock:\n",
    "            return self.term_decisions.get(en_term.lower())\n",
    "\n",
    "class TranslationState(TypedDict):\n",
    "    current_element: dict\n",
    "    draft_translation: str\n",
    "    critiques: List[str]\n",
    "    final_translation: Optional[str]\n",
    "    doc_context_manager: DocumentContextManager\n",
    "    new_decision: Optional[Dict[str, str]]\n",
    "\n",
    "print(\"Graph state defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bf5659-b2ac-4691-a4a1-44fe2177831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph workflow built successfully with all advanced features.\n",
      "Thread-safe Document Context Manager initialized.\n",
      "--- ðŸ“„ PARSING DOCUMENT (Layout-Aware) ---\n",
      "Document parsed into 3 pages.\n",
      "\n",
      "--- ðŸš€ STARTING TRANSLATION FOR 15 ELEMENTS (Workers: 1) ---\n",
      "============================================================\n",
      "Processing element 1 | Type: 'Header'\n",
      "============================================================\n",
      "============================================================\n",
      "Processing element 2 | Type: 'Title'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'VERMÃ–GENSWERTES TATSÃ„CHLICHES VERHÃ„LTNIS...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Glossary Violation: 'Sustainability Statement' should be 'NachhaltigkeitserklÃ¤rung'.\n",
      "  - Stylistic Violation: The phrase \"VERMÃ–GENSWERTES TATSÃ„CHLICHES VERHÃ„LTNIS\" is awkwardly phrased, as it contains a redundant adjective \"werts\" which is not necessary in this context.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'NachhaltigkeitserklÃ¤rung...'\n",
      "Reviser proposed new term: Sustainability Statement -> NachhaltigkeitserklÃ¤rung\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'Sustainability Statement' -> 'NachhaltigkeitserklÃ¤rung'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 3 | Type: 'UncategorizedText'\n",
      "============================================================\n",
      "============================================================\n",
      "Processing element 4 | Type: 'Title'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'GRUNDLAGE FÃœR DIE VERSORGUNG...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Glossary Violation: 'Basis for preparation' should be 'Grundlagen fÃ¼r die Erstellung'.\n",
      "  - Stylistic Violation: Die Formulierung \"GRUNDLAGE FÃœR DIE VERSORGUNG\" ist ein bisschen zu direkt und fÃ¶rmlich. Es fehlt an einem lebendigen Ton.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'Grundlagen fÃ¼r die Erstellung...'\n",
      "Reviser proposed new term: basis for preparation -> Grundlagen fÃ¼r die Erstellung\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'basis for preparation' -> 'Grundlagen fÃ¼r die Erstellung'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 5 | Type: 'NarrativeText'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'Allianz-Konzernansatz zur Nachhaltigkeitsberichterstattung...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Stylistic Violation: Die Verwendung von \"Konzernansatz\" ist hier nicht ganz passend, da \"Konzern\" im Kontext von Nachhaltigkeitsberichterstattung nicht so hÃ¤ufig verwendet wird wie in anderen Kontexten.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'Alle Allianz-Gruppenansatz zur Nachhaltigkeitsberichterstattung...'\n",
      "Reviser proposed new term: corporate approach -> Gruppenansatz\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'corporate approach' -> 'Gruppenansatz'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 6 | Type: 'NarrativeText'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'Das Ziel von Allianz â€“ Wir sichern Ihre Zukunft â€“ leitet unser Handeln im gesamten Allianz-Konzern und treibt uns dabei ...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Glossary Violation: 'Actions' should be 'MaÃŸnahmen'.\n",
      "  - Stylistic Violation: Die Phrase \"stÃ¤ndig Innovationen und Zusammenarbeit zu betreiben\" klingt etwas un natÃ¼rlich, da \"stÃ¤ndig\" normalerweise nicht mit \"Innovationen und Zusammenarbeit\" kombiniert wird.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'Wir sichern Ihre Zukunft â€“ leitet unser Handeln im gesamten Allianz-Konzern und treibt uns dabei voran, stÃ¤ndige Innovat...'\n",
      "Reviser proposed new term: constant innovation -> stÃ¤ndige Innovation\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'constant innovation' -> 'stÃ¤ndige Innovation'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 7 | Type: 'Title'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'Wie stellen wir sicher, dass MaÃŸnahmen ergriffen werden?...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Stylistic Violation: Die Formulierung \"Wie stellen wir sicher\" klingt etwas ungewÃ¶hnlich, da \"sicherstellen\" normalerweise mit \"dass\" oder \"ob\" verwendet wird, nicht mit \"wie\".\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'Wie stellen wir sicher, dass MaÃŸnahmen ergriffen werden?...'\n",
      "Reviser proposed new term: ensure -> sicherstellen\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'ensure' -> 'sicherstellen'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 8 | Type: 'NarrativeText'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'Die GeschÃ¤ftsentscheidungen der Allianz werden durch unsere Unternehmensrichtlinien geregelt und unterliegen der Aufsich...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Stylistic Violation: Die Phrasierung \"und sonstigen Richtlinien im Sinne der ESRS\" ist unklar und kÃ¶nnte durch eine prÃ¤zisere Formulierung verbessert werden.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'Die GeschÃ¤ftsentscheidungen der Allianz werden durch unsere Unternehmensrichtlinien geregelt und unterliegen der Aufsich...'\n",
      "Reviser proposed new term: corporate rules -> Unternehmensrichtlinien\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'corporate rules' -> 'Unternehmensrichtlinien'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 9 | Type: 'NarrativeText'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'Unsere Ambition ist es, in Zusammenarbeit mit unserer WertschÃ¶pfungskette den Ãœbergang zu einer nachhaltigeren Wirtschaf...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Stylistic Violation: Die Verwendung von \"nachhaltigeren Wirtschaft\" ist unklar, da \"nachhaltig\" bereits im Kontext von \"nachhaltigen Auswirkungen\" verwendet wird.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'Unsere Ambition ist es, in Zusammenarbeit mit unserer WertschÃ¶pfungskette den Ãœbergang zu einer nachhaltigeren Wirtschaf...'\n",
      "Reviser proposed new term: sustainable economy -> nachhaltige Wirtschaft\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'sustainable economy' -> 'nachhaltige Wirtschaft'\n",
      "CONTEXT MGR: Registered 'Actions' -> 'MaÃŸnahmen'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 10 | Type: 'NarrativeText'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'Ein Kernpfeiler unserer Nachhaltigkeitsziele ist es, klare, transparente Verfahren zu verfolgen und eine Ã¼berprÃ¼fbare un...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Glossary Violation: 'Sustainability Statement' should be 'NachhaltigkeitserklÃ¤rung'.\n",
      "  - Consistency Violation: 'sustainability statement' was previously set as 'NachhaltigkeitserklÃ¤rung'.\n",
      "  - Stylistic Violation: Die Verwendung des Begriffs \"Kernpfeiler\" ist hier nicht ganz natÃ¼rlich, da es sich um einen eher technischen Begriff handelt, der in diesem Kontext nicht ganz passend ist.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'Ein zentraler Bestandteil unserer Nachhaltigkeitsambitionen ist es, klare, transparente Praktiken zu verfolgen und eine ...'\n",
      "Reviser proposed new term: core pillar -> zentraler Bestandteil\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'core pillar' -> 'zentraler Bestandteil'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 11 | Type: 'Title'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'Welche Nachhaltigkeitsbelange sind fÃ¼r Allianz relevant? - MaterialitÃ¤t...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Stylistic Violation: Die Frage ist ein bisschen ungewÃ¶hnlich formuliert, da \"MaterialitÃ¤t\" normalerweise ein Begriff aus der Rechnungslegung ist und nicht direkt mit Nachhaltigkeitsbelangen zusammenhÃ¤ngt.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'Welche Nachhaltigkeitsaspekte sind fÃ¼r Allianz relevant? - MaterialitÃ¤t...'\n",
      "Reviser proposed new term: Sustainability aspects -> Nachhaltigkeitsaspekte\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'Sustainability aspects' -> 'Nachhaltigkeitsaspekte'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 12 | Type: 'Title'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'Was ist unser konkreter Ambitionsgrad?...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Stylistic Violation: Der Satz ist ein bisschen zu direkt und formell. Es fehlt an einem lebendigen Ton.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'Was ist unser Zielhoch?...'\n",
      "Reviser proposed new term: ambition level -> Zielhoch\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'ambition level' -> 'Zielhoch'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 13 | Type: 'NarrativeText'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'Soweit zutreffend, setzen wir konkrete Ziele in Bezug auf relevante Nachhaltigkeitsfragen. Diese Ziele sind unsere MaÃŸst...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Consistency Violation: 'ambition level' was previously set as 'Zielhoch'.\n",
      "  - Stylistic Violation: Die Formulierung \"soweit zutreffend\" ist hier nicht ganz natÃ¼rlich, da es sich um eine eher abstrakte Aussage handelt, die nicht direkt zum Hauptinhalt des Satzes passt.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: '\"Wo zutreffend, setzen wir konkrete Ziele in Bezug auf relevante Nachhaltigkeitsfragen. Diese Ziele sind unsere MaÃŸstÃ¤be...'\n",
      "Reviser proposed new term: ambition level -> Zielhoch\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 14 | Type: 'NarrativeText'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'âˆ’ die fÃ¼r die VorstandsvergÃ¼tung relevanten Nachhaltigkeitsziele im Abschnitt Zielprozess Vorstand und âˆ’ weitere â€žZieleâ€œ...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Stylistic Violation: Die Verwendung von â€žfÃ¼r die VorstandsvergÃ¼tung relevantenâ€œ ist etwas umstÃ¤ndlich und kÃ¶nnte durch â€žim Zusammenhang mit der VorstandsvergÃ¼tungâ€œ ersetzt werden.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'âˆ’ die im Zusammenhang mit der VorstandsvergÃ¼tung relevanten Nachhaltigkeitsziele im Abschnitt Zielprozess Vorstand und âˆ’...'\n",
      "Reviser proposed new term: in Zusammenhang mit -> im Zusammenhang mit\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'in Zusammenhang mit' -> 'im Zusammenhang mit'\n",
      "CONTEXT MGR: Registered 'Board of Management' -> 'Vorstand'\n",
      "-> Element processed and memory updated.\n",
      "============================================================\n",
      "Processing element 15 | Type: 'NarrativeText'\n",
      "============================================================\n",
      "\n",
      "--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\n",
      "Draft: 'Als TreuhÃ¤nder haben unsere VermÃ¶gensverwalter die Verantwortung, die VermÃ¶genswerte jedes Kunden gemÃ¤ÃŸ den festgelegten...'\n",
      "--- ðŸ§ MASTER CRITIQUE AGENT ---\n",
      "--- Critiques Found: ---\n",
      "  - Stylistic Violation: Die Formulierung \"wenden die Ziele von Allianz bei der Verwaltung dieser VermÃ¶genswerte von Drittkunden nicht an\" klingt etwas un natÃ¼rlich, da sie die Aussage widerspricht, dass die VermÃ¶gensverwalter ausschlieÃŸlich unter BerÃ¼cksichtigung der Portfolioziele und -richtlinien handeln.\n",
      "--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\n",
      "Revised Translation: 'Als TreuhÃ¤nder haben unsere VermÃ¶gensverwalter die Verantwortung, die VermÃ¶genswerte jedes Kunden gemÃ¤ÃŸ den festgelegten...'\n",
      "Reviser proposed new term: own targets -> eigene Ziele\n",
      "--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\n",
      "CONTEXT MGR: Registered 'own targets' -> 'eigene Ziele'\n",
      "CONTEXT MGR: Registered 'Asset managers' -> 'VermÃ¶gensverwalter'\n",
      "-> Element processed and memory updated.\n",
      "\n",
      "\n",
      "--- âœ¨ WORKFLOW COMPLETE ---\n",
      "--- ðŸ“„ Reconstructing Document with Two-Column Layout ---\n",
      "\n",
      "Layout-aware review document saved to 'review_document_layout_aware_09796236.docx'\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PART 2: AGENTIC WORKFLOW WITH ALL ENHANCEMENTS (FINAL CORRECTED)\n",
    "# ==============================================================================\n",
    "\n",
    "# 6. LANGGRAPH AGENT NODES (WITH ALL FEATURES)\n",
    "# ==============================================================================\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def initial_translator_node(state: TranslationState) -> dict:\n",
    "    \"\"\"Uses the specialist FinTranslate model with its required custom input format.\"\"\"\n",
    "    print(\"\\n--- ðŸ“ DRAFT TRANSLATOR (FinTranslate Specialist) ---\")\n",
    "    element = state[\"current_element\"]\n",
    "    source_text = element.get(\"text\", \"\")\n",
    "    if element.get(\"type\") == \"Table\":\n",
    "        source_text = extract_text_from_html(element.get(\"metadata\", {}, {}).get(\"text_as_html\", \"\"))\n",
    "    if not source_text.strip(): return {\"draft_translation\": \"\"}\n",
    "    \n",
    "    formatted_text = format_input_for_translator(source_text)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = fin_tokenizer(formatted_text, return_tensors=\"pt\", return_token_type_ids=False).to(DEVICE)\n",
    "        outputs = fin_translator_model.generate(**inputs, max_new_tokens=1024)\n",
    "        input_size = inputs[\"input_ids\"].size(1)\n",
    "        draft = fin_tokenizer.decode(outputs[0, input_size:], skip_special_tokens=True).strip()\n",
    "\n",
    "    print(f\"Draft: '{draft[:120]}...'\")\n",
    "    return {\"draft_translation\": draft}\n",
    "def rule_based_reviser_node(state: TranslationState) -> dict:\n",
    "    \"\"\"Tier 1: Handles simple, deterministic fixes without an LLM call.\"\"\"\n",
    "    print(\"--- âš™ï¸ RULE-BASED REVISER (Efficient Fixes) ---\")\n",
    "    draft = state[\"draft_translation\"]\n",
    "    revised_text = draft\n",
    "    if any(\"Formatting Violation\" in c for c in state[\"critiques\"]):\n",
    "        print(\"  > Applying German number formatting...\")\n",
    "        revised_text = format_number_de(revised_text)\n",
    "    return {\"final_translation\": revised_text}\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def llm_reviser_agent_node(state: TranslationState) -> dict:\n",
    "    \"\"\"Uses the powerful Llama 3.1 model for complex revisions and dynamic term registration.\"\"\"\n",
    "    print(\"--- ðŸ› ï¸ LLM REVISER AGENT (Llama-3.1 Generalist) ---\")\n",
    "    source_text, draft_translation, critiques = state[\"current_element\"][\"text\"], state[\"draft_translation\"], state[\"critiques\"]\n",
    "    system_prompt = \"\"\"You are an expert financial editor. Correct the flawed German translation based only on the critiques.\n",
    "    RULES:\n",
    "1. Your primary output is ONLY the final, corrected German text. No introductions or markdown.\n",
    "2. If you make a new, important terminology choice not from the glossary, output it on a new line after the translation in the format: `DECISION::[english_term]::[german_term]`\"\"\"\n",
    "    user_prompt = f\"\"\"**Source Text (English):**\n",
    "\"{source_text}\"\n",
    "**Flawed Draft (German):**\n",
    "\"{draft_translation}\"\n",
    "**Mandatory Critiques to Address:**\n",
    "- {\"- \".join(critiques)}\"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = reviser_llm.create_chat_completion(messages=messages, max_tokens=1024, temperature=0.1)\n",
    "    full_response = response['choices'][0]['message']['content'].strip()\n",
    "    final_translation, new_decision = full_response, None\n",
    "    if \"DECISION::\" in full_response:\n",
    "        lines = full_response.splitlines()\n",
    "        final_translation = \"\\n\".join([line for line in lines if not line.startswith(\"DECISION::\")])\n",
    "        decision_line = next((line for line in lines if line.startswith(\"DECISION::\")), None)\n",
    "        if decision_line:\n",
    "            parts = decision_line.split(\"::\")\n",
    "            if len(parts) == 3: new_decision = {\"en\": parts[1].strip(), \"de\": parts[2].strip()}\n",
    "    cleaned_translation = re.sub(r\"^\\s*\\*\\*.*?\\*\\*\\s*:?\\s*\", \"\", final_translation).strip()\n",
    "    print(f\"Revised Translation: '{cleaned_translation[:120]}...'\")\n",
    "    if new_decision: print(f\"Reviser proposed new term: {new_decision['en']} -> {new_decision['de']}\")\n",
    "    return {\"final_translation\": cleaned_translation, \"new_decision\": new_decision}\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. FULL CRITIC SUITE AND RECONSTRUCTOR\n",
    "# ==============================================================================\n",
    "def _critique_terminology(source_text: str, draft: str) -> List[str]:\n",
    "    critiques = []\n",
    "    for en_term, de_term in FINANCIAL_GLOSSARY.items():\n",
    "        if re.search(r'\\b' + re.escape(en_term) + r'\\b', source_text, re.IGNORECASE):\n",
    "            if not re.search(r'\\b' + re.escape(de_term) + r'\\b', draft, re.IGNORECASE):\n",
    "                critiques.append(f\"Glossary Violation: '{en_term}' should be '{de_term}'.\")\n",
    "    return critiques\n",
    "\n",
    "def _critique_formatting(draft: str) -> List[str]:\n",
    "    return [\"Formatting Violation: Numbers may be in US format.\"] if re.search(r'\\b\\d{1,3}(,\\d{3})+(\\.\\d+)?\\b', draft) else []\n",
    "\n",
    "def _critique_consistency(source_text: str, draft: str, manager: DocumentContextManager) -> List[str]:\n",
    "    critiques = []\n",
    "    for en_term in manager.term_decisions.keys():\n",
    "        if re.search(r'\\b' + re.escape(en_term) + r'\\b', source_text, re.IGNORECASE):\n",
    "            established_translation = manager.get_decision(en_term)\n",
    "            if established_translation and not re.search(r'\\b' + re.escape(established_translation) + r'\\b', draft, re.IGNORECASE):\n",
    "                critiques.append(f\"Consistency Violation: '{en_term}' was previously set as '{established_translation}'.\")\n",
    "    return critiques\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def _critique_style(draft: str) -> List[str]:\n",
    "    if not draft or len(draft.split()) < 3: return []\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a German language style checker. Analyze for awkward phrasing or unnatural tone. If an issue exists, describe it in one short sentence. If good, respond 'OK'.\"}, {\"role\": \"user\", \"content\": draft}]\n",
    "    response = reviser_llm.create_chat_completion(messages=messages, max_tokens=100, temperature=0.1)\n",
    "    critique = response['choices'][0]['message']['content'].strip()\n",
    "    return [] if \"OK\" in critique or not critique else [f\"Stylistic Violation: {critique}\"]\n",
    "def master_critique_node(state: TranslationState) -> dict:\n",
    "    print(\"--- ðŸ§ MASTER CRITIQUE AGENT ---\")\n",
    "    source_text, draft, manager = state[\"current_element\"].get(\"text\", \"\"), state.get(\"draft_translation\", \"\"), state[\"doc_context_manager\"]\n",
    "    critiques = _critique_terminology(source_text, draft) + _critique_formatting(draft) + _critique_consistency(source_text, draft, manager) + _critique_style(draft)\n",
    "    if critiques:\n",
    "        print(\"--- Critiques Found: ---\")\n",
    "        for c in critiques: print(f\"  - {c}\")\n",
    "    else:\n",
    "        print(\"--- No issues found. Approved. ---\")\n",
    "    return {\"critiques\": critiques}\n",
    "\n",
    "def final_reconstructor_node(state: TranslationState) -> dict:\n",
    "    print(\"--- âœ… FINAL RECONSTRUCTOR & MEMORY UPDATE ---\")\n",
    "    final_text, source_text, manager = state.get(\"final_translation\") or state.get(\"draft_translation\", \"\"), state[\"current_element\"][\"text\"], state[\"doc_context_manager\"]\n",
    "    new_decision = state.get(\"new_decision\")\n",
    "    if new_decision: manager.register_decision(new_decision['en'], new_decision['de'])\n",
    "    for en_term, de_term in FINANCIAL_GLOSSARY.items():\n",
    "        if re.search(r'\\b' + re.escape(en_term) + r'\\b', source_text, re.IGNORECASE) and re.search(r'\\b' + re.escape(de_term) + r'\\b', final_text, re.IGNORECASE):\n",
    "            manager.register_decision(en_term, de_term)\n",
    "    final_element = state[\"current_element\"].copy()\n",
    "    final_element.update({\"original_text\": source_text, \"translated_text\": final_text, \"critiques_found\": state.get(\"critiques\", [])})\n",
    "    print(\"-> Element processed and memory updated.\")\n",
    "    return {\"final_translation\": final_element}\n",
    "\n",
    "# ==============================================================================\n",
    "# 8. GRAPH CONSTRUCTION AND EXECUTION\n",
    "# ==============================================================================\n",
    "def build_graph():\n",
    "    workflow = StateGraph(TranslationState)\n",
    "    nodes = {\"translator\": initial_translator_node, \"master_critic\": master_critique_node, \"rule_based_reviser\": rule_based_reviser_node, \"llm_reviser\": llm_reviser_agent_node, \"reconstructor\": final_reconstructor_node}\n",
    "    for name, node in nodes.items(): workflow.add_node(name, node)\n",
    "    workflow.set_entry_point(\"translator\")\n",
    "    workflow.add_edge(\"translator\", \"master_critic\")\n",
    "    workflow.add_edge(\"rule_based_reviser\", \"reconstructor\")\n",
    "    workflow.add_edge(\"llm_reviser\", \"reconstructor\")\n",
    "    def route_after_critique(state: TranslationState) -> str:\n",
    "        critiques = state.get(\"critiques\", [])\n",
    "        if not critiques: return \"reconstructor\"\n",
    "        return \"rule_based_reviser\" if {c.split(\":\")[0] for c in critiques}.issubset({\"Formatting Violation\"}) else \"llm_reviser\"\n",
    "    workflow.add_conditional_edges(\"master_critic\", route_after_critique, {\"reconstructor\": \"reconstructor\", \"rule_based_reviser\": \"rule_based_reviser\", \"llm_reviser\": \"llm_reviser\"})\n",
    "    workflow.add_edge(\"reconstructor\", END)\n",
    "    print(\"LangGraph workflow built successfully with all advanced features.\")\n",
    "    return workflow.compile()\n",
    "\n",
    "def document_parser(path: str) -> List[dict]:\n",
    "    print(\"--- ðŸ“„ PARSING DOCUMENT ---\")\n",
    "    if not os.path.exists(path): raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    elements = partition_pdf(filename=path, strategy=\"hi_res\", infer_table_structure=True, model_name=\"yolox\", languages=['eng'])\n",
    "    print(f\"Document parsed into {len(elements)} elements.\")\n",
    "    return [el.to_dict() for el in elements]\n",
    "def create_review_document(filename: str, processed_elements: List[dict]):\n",
    "    doc = Document()\n",
    "    doc.add_heading('Financial Translation Review', 0)\n",
    "    for element in processed_elements:\n",
    "        if not element: continue\n",
    "        doc.add_heading(f\"Element Type: {element.get('type', 'N/A')}\", level=2)\n",
    "        table = doc.add_table(rows=1, cols=2); table.style = 'Table Grid'\n",
    "        hdr_cells = table.rows[0].cells; hdr_cells[0].text = 'Original (English)'; hdr_cells[1].text = 'Translated (German)'\n",
    "        row_cells = table.add_row().cells; row_cells[0].text = element.get('original_text', ''); row_cells[1].text = element.get('translated_text', '')\n",
    "        if element.get(\"critiques_found\"):\n",
    "            doc.add_paragraph(\"Critiques Found:\", style='Intense Quote')\n",
    "            for critique in element[\"critiques_found\"]: doc.add_paragraph(critique, style='List Bullet')\n",
    "        doc.add_page_break()\n",
    "    doc.save(filename)\n",
    "    print(f\"\\nReview document saved to '{filename}'\")\n",
    "\n",
    "def process_element_task(args):\n",
    "    \"\"\"Worker function for parallel/sequential processing.\"\"\"\n",
    "    i, element, app, doc_manager = args\n",
    "    print(\"=\"*60 + f\"\\nProcessing element {i+1} | Type: '{element.get('type', 'UncategorizedText')}'\\n\" + \"=\"*60)\n",
    "    if element.get(\"type\", \"UncategorizedText\") not in [\"NarrativeText\", \"Title\", \"ListItem\", \"Table\"]:\n",
    "        skipped_element = element.copy()\n",
    "        skipped_element[\"translated_text\"] = f\"SKIPPED: Type '{element.get('type')}'\"\n",
    "        skipped_element[\"original_text\"] = element[\"text\"]\n",
    "        return i, skipped_element\n",
    "    initial_state = {\"current_element\": element, \"doc_context_manager\": doc_manager}\n",
    "    try:\n",
    "        final_state = app.invoke(initial_state)\n",
    "        return i, final_state.get('final_translation')\n",
    "    except Exception as e:\n",
    "        error_element = element.copy()\n",
    "        error_element[\"translated_text\"] = f\"ERROR: {e}\"\n",
    "        error_element[\"original_text\"] = element[\"text\"]\n",
    "        return i, error_element\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 2: AGENTIC WORKFLOW WITH LAYOUT-AWARE I/O\n",
    "# ==============================================================================\n",
    "\n",
    "# --- No changes to the Agent Nodes (6), Critic Suite (7), or Graph Builder (8) ---\n",
    "# The core translation engine remains the same.\n",
    "# We are only changing Section 9: The I/O and Execution Logic.\n",
    "# For brevity, I am omitting the unchanged sections (6, 7, 8). They should be copied from the previous final version.\n",
    "\n",
    "# ==============================================================================\n",
    "# 9. ADVANCED DOCUMENT PARSING AND RECONSTRUCTION\n",
    "# ==============================================================================\n",
    "\n",
    "def document_parser(path: str) -> Dict[int, List[dict]]:\n",
    "    \"\"\"\n",
    "    Parses the PDF and returns elements grouped by page number.\n",
    "    This is crucial for page-by-page layout analysis.\n",
    "    \"\"\"\n",
    "    print(\"--- ðŸ“„ PARSING DOCUMENT (Layout-Aware) ---\")\n",
    "    if not os.path.exists(path): raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    \n",
    "    # The 'coordinates' metadata is essential for layout detection\n",
    "    elements = partition_pdf(filename=path, strategy=\"hi_res\", infer_table_structure=True, model_name=\"yolox\", languages=['eng'], include_page_breaks=True, extract_element_types=True)\n",
    "    \n",
    "    paged_elements = {}\n",
    "    current_page = 1\n",
    "    for el in elements:\n",
    "        if el.category == \"PageBreak\":\n",
    "            current_page += 1\n",
    "            continue\n",
    "        \n",
    "        if current_page not in paged_elements:\n",
    "            paged_elements[current_page] = []\n",
    "            \n",
    "        # We must store the element as a dict to add our own metadata\n",
    "        el_dict = el.to_dict()\n",
    "        paged_elements[current_page].append(el_dict)\n",
    "\n",
    "    print(f\"Document parsed into {len(paged_elements)} pages.\")\n",
    "    return paged_elements\n",
    "\n",
    "def group_elements_by_column(page_elements: List[dict], page_width: float, full_width_threshold=0.7) -> Dict[str, List[dict]]:\n",
    "    \"\"\"\n",
    "    Takes a list of elements from a single page and groups them into\n",
    "    'full_width', 'left_column', and 'right_column'.\n",
    "    \"\"\"\n",
    "    columns = {\"full_width\": [], \"left_column\": [], \"right_column\": []}\n",
    "    page_midpoint = page_width / 2\n",
    "\n",
    "    for el in page_elements:\n",
    "        coords = el.get(\"metadata\", {}).get(\"coordinates\")\n",
    "        if not coords:\n",
    "            columns[\"full_width\"].append(el)\n",
    "            continue\n",
    "            \n",
    "        (x1, y1), _, (x2, y2), _ = coords.get(\"points\")\n",
    "        el_width = x2 - x1\n",
    "        el_center_x = (x1 + x2) / 2\n",
    "\n",
    "        if el_width > page_width * full_width_threshold:\n",
    "            columns[\"full_width\"].append(el)\n",
    "        elif el_center_x < page_midpoint:\n",
    "            columns[\"left_column\"].append(el)\n",
    "        else:\n",
    "            columns[\"right_column\"].append(el)\n",
    "            \n",
    "    # Sort each column by vertical position\n",
    "    for key in columns:\n",
    "        columns[key].sort(key=lambda item: item.get(\"metadata\", {}).get(\"coordinates\", {}).get(\"points\", [[0,0]])[0][1])\n",
    "\n",
    "    return columns\n",
    "\n",
    "def add_elements_to_cell(cell, elements, doc):\n",
    "    \"\"\"Helper to add a list of processed elements to a table cell with robust string casting.\"\"\"\n",
    "    for element in elements:\n",
    "        # THE FIX IS HERE: Use str() to prevent errors from non-string data\n",
    "        text_to_add = str(element.get('translated_text', ''))\n",
    "        p = cell.add_paragraph(text_to_add)\n",
    "        p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY\n",
    "        cell.add_paragraph('') # Add a space between elements\n",
    "\n",
    "def create_review_document_with_columns(filename: str, paged_translated_elements: Dict[int, List[dict]]):\n",
    "    \"\"\"\n",
    "    Creates a Word document that reconstructs the two-column layout using a table.\n",
    "    This version includes robust string casting to prevent errors.\n",
    "    \"\"\"\n",
    "    print(\"--- ðŸ“„ Reconstructing Document with Two-Column Layout ---\")\n",
    "    doc = Document()\n",
    "    doc.sections[0].left_margin = Inches(0.5)\n",
    "    doc.sections[0].right_margin = Inches(0.5)\n",
    "\n",
    "    for page_num, elements in sorted(paged_translated_elements.items()):\n",
    "        page_width = 595 # A4 width in points\n",
    "        grouped_cols = group_elements_by_column(elements, page_width)\n",
    "        \n",
    "        # THE FIX IS HERE: Use str() to prevent errors\n",
    "        doc.add_heading(f\"Page {page_num}\", level=1)\n",
    "\n",
    "        for el in grouped_cols[\"full_width\"]:\n",
    "            # THE FIX IS HERE: Use str() to prevent errors\n",
    "            text_to_add = str(el.get('translated_text', ''))\n",
    "            p = doc.add_paragraph(text_to_add)\n",
    "            if el.get('type') == 'Title':\n",
    "                p.style = 'Heading 2'\n",
    "            doc.add_paragraph('') # Spacer\n",
    "\n",
    "        if grouped_cols[\"left_column\"] or grouped_cols[\"right_column\"]:\n",
    "            table = doc.add_table(rows=1, cols=2)\n",
    "            table.autofit = False\n",
    "            table.allow_autofit = False\n",
    "            table.style = 'Table Grid'\n",
    "            \n",
    "            table.columns[0].width = Inches(3.75)\n",
    "            table.columns[1].width = Inches(3.75)\n",
    "            \n",
    "            left_cell = table.cell(0, 0)\n",
    "            right_cell = table.cell(0, 1)\n",
    "            \n",
    "            add_elements_to_cell(left_cell, grouped_cols[\"left_column\"], doc)\n",
    "            add_elements_to_cell(right_cell, grouped_cols[\"right_column\"], doc)\n",
    "\n",
    "        if page_num < len(paged_translated_elements):\n",
    "            doc.add_page_break()\n",
    "            \n",
    "    doc.save(filename)\n",
    "    print(f\"\\nLayout-aware review document saved to '{filename}'\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 10. MAIN EXECUTION BLOCK (MODIFIED FOR LAYOUT-AWARE PROCESSING)\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you copy the unchanged functions here:\n",
    "    # build_graph(), process_element_task(), etc. from the previous final code.\n",
    "    # The only change is how we call them.\n",
    "\n",
    "    app = build_graph() # Unchanged\n",
    "    doc_manager = DocumentContextManager() # Unchanged\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Parse the document page by page\n",
    "        paged_source_elements = document_parser(ENGLISH_PDF_PATH)\n",
    "        \n",
    "        all_elements_to_process = []\n",
    "        for page_num, elements in paged_source_elements.items():\n",
    "            # Flatten the list for the translation pool, but keep page info if needed\n",
    "            for el in elements:\n",
    "                el['page_num'] = page_num # Tag element with its page number\n",
    "                all_elements_to_process.append(el)\n",
    "        \n",
    "        elements_to_process = all_elements_to_process[:MAX_ELEMENTS_TO_PROCESS]\n",
    "        print(f\"\\n--- ðŸš€ STARTING TRANSLATION FOR {len(elements_to_process)} ELEMENTS (Workers: {NUM_WORKERS}) ---\")\n",
    "\n",
    "        # Step 2: Translate all elements in parallel (the engine is layout-agnostic)\n",
    "        tasks = [(i, element, app, doc_manager) for i, element in enumerate(elements_to_process)]\n",
    "        results_map = {}\n",
    "        with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "            # The worker function `process_element_task` is unchanged\n",
    "            future_to_task = {executor.submit(process_element_task, task): task for task in tasks}\n",
    "            for future in as_completed(future_to_task):\n",
    "                # We get the original element back to preserve its metadata\n",
    "                original_task_args = future_to_task[future]\n",
    "                original_element = original_task_args[1]\n",
    "                \n",
    "                _, translated_element_data = future.result()\n",
    "                \n",
    "                # Merge the translation result back into the original element data\n",
    "                original_element.update(translated_element_data)\n",
    "                results_map[id(original_element)] = original_element\n",
    "\n",
    "        # Step 3: Re-group the translated elements by page for reconstruction\n",
    "        paged_translated_elements = {}\n",
    "        for element in all_elements_to_process:\n",
    "            if id(element) in results_map:\n",
    "                page_num = element['page_num']\n",
    "                if page_num not in paged_translated_elements:\n",
    "                    paged_translated_elements[page_num] = []\n",
    "                paged_translated_elements[page_num].append(results_map[id(element)])\n",
    "\n",
    "        print(\"\\n\\n--- âœ¨ WORKFLOW COMPLETE ---\")\n",
    "\n",
    "        # Step 4: Reconstruct the final document with the two-column layout\n",
    "        output_file_docx = f\"review_document_layout_aware_{str(uuid.uuid4())[:8]}.docx\"\n",
    "        create_review_document_with_columns(output_file_docx, paged_translated_elements)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- âŒ A FATAL ERROR OCCURRED ---\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b310d2-e1b6-45f9-8d5b-ac672e48f6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
