import json
from pathlib import Path
from typing import List, Dict, Any

import config

ContentItem = Dict[str, Any]

def process_document_json(doc_intelligence_data: Any) -> List[ContentItem]:
    """
    MODIFIED (THE FIX):
    Removed the 'table_offsets' logic that was incorrectly skipping paragraphs,
    list items, and other content that fell within a table's span.
    
    This parser now extracts ALL items from 'paragraphs' and 'tables'
    and returns a single, offset-sorted list.
    """
    # Allow passing a file path or a preloaded dict
    if isinstance(doc_intelligence_data, (str, Path)):
        with open(Path(doc_intelligence_data), 'r', encoding='utf-8') as f:
            doc_intelligence_data = json.load(f)

    try:
        analyze_result = doc_intelligence_data['analyzeResult']
        # We now get the content directly from the items, not the global markdown string
        raw_paragraphs = analyze_result.get('paragraphs', [])
        pages = analyze_result.get('pages', [])
        raw_tables = analyze_result.get('tables', [])
    except KeyError as e:
        raise ValueError(f"Document Intelligence data is missing expected key: {e}") from e

    # --- Step 1: Create a quick lookup for page number by span offset ---
    # We still need this to associate tables with their page number
    page_lookup = {}
    for page in pages:
        for span in page.get('spans', []):
            for i in range(span['offset'], span['offset'] + span['length']):
                page_lookup[i] = page.get('pageNumber', 0)

    # --- Step 2: Extract all content items ---
    all_content: List[ContentItem] = []

    # Process PARAGRAPHS (includes sectionHeading, title, listItem, footnote, etc.)
    for p in raw_paragraphs:
        role = p.get('role', 'paragraph')
        if role in config.IGNORED_ROLES or not p.get('spans'):
            continue

        offset = p['spans'][0]['offset']
        
        # --- BUG FIX ---
        # The 'if offset in table_offsets:' check has been REMOVED.
        # We now extract all paragraphs regardless of their position relative to tables.
        # --- END FIX ---
        
        text = p.get('content', '').strip()
        page_number = page_lookup.get(offset, 0)
        
        if text:
            all_content.append({
                'text': text, 
                'type': role, 
                'page': page_number, 
                'offset': offset
            })

    # Process TABLES
    for table in raw_tables:
        if not table.get('spans'):
            continue
        
        offset = table['spans'][0]['offset']
        page_number = page_lookup.get(offset, 0)
        
        # Extract the pre-formatted <table> content directly from the table object
        # Note: 'content' is not a standard field on the table object, we use 'cells' to build it.
        # Let's use the 'spans' to get the content from the *full markdown string*
        # (Re-reading the client: `output_content_format="markdown"`)
        
        # Re-add the full content string
        full_text_content = analyze_result.get('content', '')
        if full_text_content:
            length = table['spans'][0]['length']
            table_html = full_text_content[offset : offset + length].strip()
        else:
            # Fallback if markdown content isn't available
            table_html = "Table Content (Fallback)"

        if table_html:
            all_content.append({
                'text': table_html, 
                'type': 'table', 
                'page': page_number, 
                'offset': offset
            })

    # --- Step 3: Sort all extracted content by its character offset ---
    all_content.sort(key=lambda x: x['offset'])
    
    # We return the raw, sorted list of ALL items.
    return all_content
