# test_1/src/processing/json_parser.py
import json
from pathlib import Path
from typing import List, Dict, Any

import config

# A type alias for our structured content for clarity
ContentItem = Dict[str, Any]


# --- FIX for Flaw 7: Robust table conversion ---
def _convert_table_to_markdown(table_obj: Dict) -> str:
    """Converts an Azure table object into a Markdown string, handling row/col spans."""
    if not table_obj.get('cells'):
        return ""

    row_count = table_obj.get('rowCount', 0)
    col_count = table_obj.get('columnCount', 0)

    if row_count == 0 or col_count == 0:
        # Cannot process table without dimensions, return raw content if possible
        spans = table_obj.get('spans', [])
        if spans:
            # This requires access to the full document content, which this function doesn't have.
            # Returning empty is the safest fallback.
            return ""
        return ""

    # A grid to hold the final text content
    grid = [["" for _ in range(col_count)] for _ in range(row_count)]
    # A shadow grid to track occupied cells (due to spans)
    occupied = [[False for _ in range(col_count)] for _ in range(row_count)]

    header_row_indices = set()

    # Sort cells to process top-left ones first, ensuring consistent filling
    cells = sorted(table_obj.get('cells', []), key=lambda x: (x.get('rowIndex', 0), x.get('columnIndex', 0)))

    for cell in cells:
        r = cell.get('rowIndex', 0)
        c = cell.get('columnIndex', 0)

        # Skip anomalous cells outside the defined grid
        if r >= row_count or c >= col_count:
            continue

        # Find the next available column in the current row if this one is occupied
        while c < col_count and occupied[r][c]:
            c += 1

        if c >= col_count:
            continue  # Row is full, this cell is anomalous

        content = cell.get('content', '').strip().replace('\n', ' ')  # Clean content
        row_span = cell.get('rowSpan', 1)
        col_span = cell.get('columnSpan', 1)

        # Place the content in the grid
        grid[r][c] = content

        # Mark all cells covered by this span as occupied
        for i in range(r, min(r + row_span, row_count)):
            for j in range(c, min(c + col_span, col_count)):
                occupied[i][j] = True

        if cell.get('kind') == 'columnHeader':
            # Mark all rows this header cell spans as part of the header
            for i in range(r, min(r + row_span, row_count)):
                header_row_indices.add(i)

    markdown_str = ""
    separator_generated = False

    # Now, build the markdown string from the grid
    for r_idx in range(row_count):
        # Filter out cells that were "occupied" but not the start of a span
        # No, we need all cells for the final grid structure.
        row_cells = [grid[r_idx][c_idx] for c_idx in range(col_count)]
        markdown_str += "| " + " | ".join(row_cells) + " |\n"

        # If this was a header row, and we haven't made the separator yet, add it
        if r_idx in header_row_indices and not separator_generated:
            # Check if the *next* row is NOT a header row
            if (r_idx + 1) >= row_count or (r_idx + 1) not in header_row_indices:
                markdown_str += "| " + " | ".join(["---"] * col_count) + " |\n"
                separator_generated = True

    # In case the *only* row was a header row
    if not separator_generated and len(header_row_indices) > 0:
        markdown_str += "| " + " | ".join(["---"] * col_count) + " |\n"

    return markdown_str.strip()
# --- END FIX ---


def process_document_json(doc_intelligence_data: Any) -> List[ContentItem]:
    # Allow passing a file path or a preloaded dict
    if isinstance(doc_intelligence_data, (str, Path)):
        with open(Path(doc_intelligence_data), 'r', encoding='utf-8') as f:
            doc_intelligence_data = json.load(f)

    try:
        analyze_result = doc_intelligence_data['analyzeResult']
        full_text_content = analyze_result['content']
        raw_paragraphs = analyze_result.get('paragraphs', [])
        pages = analyze_result.get('pages', [])
        raw_tables = analyze_result.get('tables', [])
    except KeyError as e:
        raise ValueError(f"Document Intelligence data is missing expected key: {e}") from e

    # --- Step 1: Identify all character offsets belonging to tables to avoid duplication ---
    table_offsets = set()
    for table in raw_tables:
        for span in table.get('spans', []):
            for i in range(span['offset'], span['offset'] + span['length']):
                table_offsets.add(i)

    # Identify all character offsets that are handwritten
    handwritten_offsets = set()
    if 'styles' in analyze_result:
        for style in analyze_result['styles']:
            if style.get('isHandwritten') and style.get('spans'):
                for span in style['spans']:
                    for i in range(span['offset'], span['offset'] + span['length']):
                        handwritten_offsets.add(i)

    # Create a quick lookup for page number by span offset
    page_lookup = {}
    for page in pages:
        for span in page.get('spans', []):
            for i in range(span['offset'], span['offset'] + span['length']):
                page_lookup[i] = page.get('pageNumber', 0)

    # --- Step 2: Extract all content, including tables, and sort by position ---
    all_content: List[ContentItem] = []

    # Process PARAGRAPHS
    for p in raw_paragraphs:
        role = p.get('role', 'paragraph')
        if role in config.IGNORED_ROLES or not p.get('spans'):
            continue

        offset = p['spans'][0]['offset']
        # If the paragraph is inside a table or is handwritten, SKIP it.
        if offset in table_offsets or offset in handwritten_offsets:
            continue

        length = p['spans'][0]['length']
        text = full_text_content[offset : offset + length].strip()
        page_number = page_lookup.get(offset, 0)
        if text:
            all_content.append({'text': text, 'type': role, 'page': page_number, 'offset': offset})

    # Process TABLES
    for table in raw_tables:
        if not table.get('spans'):
            continue
        offset = table['spans'][0]['offset']
        page_number = page_lookup.get(offset, 0)
        markdown_table = _convert_table_to_markdown(table)
        if markdown_table:
            all_content.append({'text': markdown_table, 'type': 'table', 'page': page_number, 'offset': offset})

    # Sort all extracted content by its character offset to maintain document order
    all_content.sort(key=lambda x: x['offset'])

    # --- Step 3: Stitch broken paragraphs ---
    final_content: List[ContentItem] = []
    stitched_text = ""
    current_page = 0
    current_type = "paragraph"

    for i, segment in enumerate(all_content):
        # If the current element is a table or a structural heading, finalize the previous stitched text.
        is_standalone = segment['type'] in config.STRUCTURAL_ROLES or segment['type'] == 'table'

        if is_standalone:
            if stitched_text:  # Finalize any pending paragraph
                final_content.append({'text': stitched_text, 'type': current_type, 'page': current_page})
                stitched_text = ""
            final_content.append(segment)  # Add the standalone item
            continue

        # This logic handles stitching of regular paragraphs
        if not stitched_text:  # Start a new paragraph
            stitched_text = segment['text']
            current_page = segment['page']
            current_type = segment['type']
        else:
            # If previous text ends with punctuation, start a new paragraph
            if stitched_text.endswith(('.', '!', '?', ':', 'â€¢')):
                final_content.append({'text': stitched_text, 'type': current_type, 'page': current_page})
                stitched_text = segment['text']
                current_page = segment['page']
                current_type = segment['type']
            else:  # Continue stitching the current paragraph
                stitched_text += f" {segment['text']}"

    # Add the last stitched paragraph if it exists
    if stitched_text:
        final_content.append({'text': stitched_text, 'type': current_type, 'page': current_page})

    return final_content
