# --- FastAPI & Standard Lib Imports ---
import io
import base64
import traceback
import json
import asyncio  # <-- NEW: For async operations
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, AsyncGenerator

from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse  # <-- NEW: For SSE

# --- Import your project modules ---
import config
from src.clients.doc_intelligence_client import analyze_pdf
from src.processing.json_parser import process_document_json
from src.processing.toc_parser import get_toc_text_from_pdf_bytes, structure_toc
from src.alignment.toc_aligner import align_tocs
from src.alignment.semantic_aligner import align_content
from src.evaluation.pipeline import run_evaluation_pipeline
from src.reporting.excel_writer import (
    create_excel_report_in_memory,
    save_alignment_report,
    save_evaluation_report,
    save_sectionwise_debug_report
)

# --- FastAPI App Initialization ---
app = FastAPI(
    title="Translation Evaluator API",
    description="Analyzes and evaluates translated PDF documents."
)

# --- CORS Configuration (CRITICAL) ---
origins = [
    "http://localhost:5173",  # Default Vite port
    "http://localhost:3000",  # Default Create React App port
    "http://localhost",
    "http://127.0.0.1",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- Helper to format SSE messages ---
def format_sse_message(data: Dict[str, Any]) -> str:
    """Formats a dictionary as a Server-Sent Event string."""
    json_data = json.dumps(data)
    return f"data: {json_data}\n\n"


# --- The Streaming Analysis Generator ---
async def run_analysis_stream(
    eng_pdf_bytes: bytes,
    ger_pdf_bytes: bytes,
    eng_filename: str,
    ger_filename: str,
    alignment_mode: str,
    toc_page_num: int
) -> AsyncGenerator[str, None]:
    """
    This generator function performs the analysis and yields
    status updates as Server-Sent Events.
    """
    output_dir = Path(config.OUTPUT_DIR)
    output_dir.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_filename = f"{Path(eng_filename).stem}_{timestamp}"
    
    try:
        # --- Step 1: Azure Document Intelligence ---
        yield format_sse_message({"status": "progress", "message": "Step 1/5: Connecting to Document Intelligence..."})
        
        # Run blocking I/O in a separate thread
        eng_json_data_task = asyncio.to_thread(analyze_pdf, eng_pdf_bytes, eng_filename)
        ger_json_data_task = asyncio.to_thread(analyze_pdf, ger_pdf_bytes, ger_filename)
        eng_json_data, ger_json_data = await asyncio.gather(eng_json_data_task, ger_json_data_task)
        
        # --- Step 2: Processing full document content ---
        yield format_sse_message({"status": "progress", "message": "Step 2/5: Processing and structuring content..."})
        
        full_english_content_task = asyncio.to_thread(process_document_json, eng_json_data)
        full_german_content_task = asyncio.to_thread(process_document_json, ger_json_data)
        full_english_content, full_german_content = await asyncio.gather(full_english_content_task, full_german_content_task)

        final_aligned_pairs: List[Dict[str, Any]] = []

        # ---
        # --- START: WORKFLOW SPLIT ---
        # ---
        
        if alignment_mode == "ToC-Based":
            yield format_sse_message({"status": "progress", "message": "Step 3/5: Aligning Table of Contents..."})
            
            # --- ToC Extraction ---
            eng_toc_page_idx = max(0, toc_page_num - 1)
            eng_toc_task = asyncio.to_thread(get_toc_text_from_pdf_bytes, eng_pdf_bytes, page_num=eng_toc_page_idx)
            ger_toc_task = asyncio.to_thread(get_toc_text_from_pdf_bytes, ger_pdf_bytes, page_num=eng_toc_page_idx)
            eng_toc_text, ger_toc_text = await asyncio.gather(eng_toc_task, ger_toc_task)
            
            english_toc_task = asyncio.to_thread(structure_toc, eng_toc_text)
            german_toc_task = asyncio.to_thread(structure_toc, ger_toc_text)
            english_toc, german_toc = await asyncio.gather(english_toc_task, german_toc_task)

            aligned_sections = await asyncio.to_thread(align_tocs, english_toc, german_toc)

            # --- Section-wise Alignment ---
            yield format_sse_message({"status": "progress", "message": "Step 4/5: Performing section-wise alignment..."})
            section_debug_data = {}
            for i, section in enumerate(aligned_sections):
                eng_sec, ger_sec = section['english'], section['german']
                
                eng_section_content = [item for item in full_english_content if eng_sec['start_page'] <= item['page'] <= eng_sec['end_page']]
                ger_section_content = [item for item in full_german_content if ger_sec['start_page'] <= item['page'] <= ger_sec['end_page']]

                if eng_section_content and ger_section_content:
                    # This is the most CPU-intensive part
                    aligned_pairs_section = await asyncio.to_thread(align_content, eng_section_content, ger_section_content, context_window=1)
                    final_aligned_pairs.extend(aligned_pairs_section)
                    section_debug_data[eng_sec['title']] = aligned_pairs_section
            
            # --- Save Debug Reports (Non-blocking) ---
            final_aligned_pairs.sort(key=lambda x: (x['english']['page'] if x.get('english') else float('inf')))
            debug_report_path = output_dir / f"debug_report_{base_filename}.xlsx"
            await asyncio.to_thread(save_sectionwise_debug_report, section_debug_data, debug_report_path)

        
        else: # Full Document (Direct)
            yield format_sse_message({"status": "progress", "message": "Step 3/5: Generating text embeddings..."})
            
            # --- Step 3/5: Performing semantic alignment ---
            # This is the most CPU-intensive part
            final_aligned_pairs = await asyncio.to_thread(
                align_content,
                full_english_content,
                full_german_content,
                context_window=1,
            )
            yield format_sse_message({"status": "progress", "message": "Step 4/5: Performing semantic alignment..."})

        # ---
        # --- END: WORKFLOW SPLIT ---
        # ---
        
        # --- Step 4/5: Evaluating aligned pairs ---
        yield format_sse_message({"status": "progress", "message": "Step 5/5: Evaluating translation pairs..."})
        evaluation_results = await asyncio.to_thread(run_evaluation_pipeline, final_aligned_pairs)

        # --- Step 5/5: Saving reports and preparing response ---
        yield format_sse_message({"status": "progress", "message": "Finalizing analysis..."})
        
        # --- Create Excel report in memory ---
        excel_data_bytes = await asyncio.to_thread(create_excel_report_in_memory, evaluation_results)
        report_base64 = base64.b64encode(excel_data_bytes).decode('utf-8')
        
        # --- Save reports to disk (can be done in parallel) ---
        alignment_report_path = output_dir / f"alignment_{base_filename}.xlsx"
        save_align_task = asyncio.to_thread(save_alignment_report, final_aligned_pairs, alignment_report_path)
        
        save_eval_task = None
        if evaluation_results:
            eval_report_path = output_dir / f"evaluation_{base_filename}.xlsx"
            save_eval_task = asyncio.to_thread(save_evaluation_report, evaluation_results, eval_report_path)
        
        await save_align_task
        if save_eval_task:
            await save_eval_task

        # --- FINAL MESSAGE: Send all data to the client ---
        yield format_sse_message({
            "status": "complete",
            "findings": evaluation_results,
            "report_base64": report_base64
        })

    except Exception as e:
        print(f"FATAL: An error occurred during analysis: {e}")
        traceback.print_exc()
        # --- ERROR MESSAGE: Send the error to the client ---
        yield format_sse_message({
            "status": "error",
            "message": f"An internal server error occurred: {e}"
        })


# --- Health Check Endpoint ---
@app.get("/", tags=["Status"])
async def root():
    """A simple health check endpoint."""
    return {"message": "Translation Evaluator API is running"}


# --- Main Analysis Endpoint (Now returns a StreamingResponse) ---
@app.post("/analyze", tags=["Analysis"])
async def analyze_documents(
    english_pdf: UploadFile = File(..., description="The source English PDF file"),
    german_pdf: UploadFile = File(..., description="The translated German PDF file"),
    alignment_mode: str = Form(..., description="Either 'ToC-Based' or 'Full Document'"),
    toc_page_num: int = Form(1, description="The page number of the ToC (1-indexed)")
):
    """
    Analyzes, aligns, and evaluates two PDF documents.
    
    This endpoint now streams status updates (SSE) and returns
    the final result as the last message.
    """
    try:
        eng_pdf_bytes = await english_pdf.read()
        ger_pdf_bytes = await german_pdf.read()

        return StreamingResponse(
            run_analysis_stream(
                eng_pdf_bytes,
                ger_pdf_bytes,
                english_pdf.filename,
                german_pdf.filename,
                alignment_mode,
                toc_page_num
            ),
            media_type="text/event-stream"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"An error occurred reading files: {e}"
        )

# --- To run this server ---
# 1. Make sure your venv is active
# 2. In your /backend/ folder, run:
#    uvicorn main:app --reload
