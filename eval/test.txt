# --- FastAPI & Standard Lib Imports ---
import io
import base64
import traceback
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

# --- Import your project modules ---
import config
from src.clients.doc_intelligence_client import analyze_pdf
from src.processing.json_parser import process_document_json
from src.processing.toc_parser import get_toc_text_from_pdf_bytes, structure_toc
from src.alignment.toc_aligner import align_tocs
from src.alignment.semantic_aligner import align_content
from src.evaluation.pipeline import run_evaluation_pipeline
from src.reporting.excel_writer import (
    create_excel_report_in_memory,
    save_alignment_report,
    save_evaluation_report,
    save_sectionwise_debug_report
)

# --- FastAPI App Initialization ---
app = FastAPI(
    title="Translation Evaluator API",
    description="Analyzes and evaluates translated PDF documents."
)

# --- CORS Configuration (CRITICAL) ---
# This allows your React frontend (running on localhost:5173) 
# to communicate with this backend (running on localhost:8000).
origins = [
    "http://localhost:5173",  # Default Vite port
    "http://localhost:3000",  # Default Create React App port
    "http://localhost",
    "http://127.0.0.1",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods (GET, POST, etc.)
    allow_headers=["*"],  # Allows all headers
)


# --- Health Check Endpoint ---
@app.get("/", tags=["Status"])
async def root():
    """A simple health check endpoint."""
    return {"message": "Translation Evaluator API is running"}


# --- Main Analysis Endpoint ---
@app.post("/analyze", tags=["Analysis"])
async def analyze_documents(
    english_pdf: UploadFile = File(..., description="The source English PDF file"),
    german_pdf: UploadFile = File(..., description="The translated German PDF file"),
    alignment_mode: str = Form(..., description="Either 'ToC-Based' or 'Full Document'"),
    toc_page_num: int = Form(1, description="The page number of the ToC (1-indexed)")
):
    """
    Analyzes, aligns, and evaluates two PDF documents.
    
    This single endpoint replicates the entire Streamlit workflow.
    """
    
    output_dir = Path(config.OUTPUT_DIR)
    output_dir.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_filename = f"{Path(english_pdf.filename).stem}_{timestamp}"

    try:
        # --- Read file bytes from the upload ---
        print("Reading uploaded PDF bytes...")
        eng_pdf_bytes = await english_pdf.read()
        ger_pdf_bytes = await german_pdf.read()

        # Local variable to store results, replacing st.session_state
        evaluation_results: List[Dict[str, Any]] = []
        final_aligned_pairs: List[Dict[str, Any]] = []

        # --- Step 1: Azure Document Intelligence ---
        print("Step 1: Analyzing PDFs with Azure Document Intelligence...")
        eng_json_data = analyze_pdf(eng_pdf_bytes, english_pdf.filename)
        ger_json_data = analyze_pdf(ger_pdf_bytes, german_pdf.filename)

        # --- Step 2: Processing full document content ---
        print("Step 2: Processing full document content...")
        full_english_content = process_document_json(eng_json_data)
        full_german_content = process_document_json(ger_json_data)
        print(f"Extracted {len(full_english_content)} EN segments and {len(full_german_content)} DE segments.")

        # ---
        # --- START: WORKFLOW SPLIT ---
        # ---
        
        if alignment_mode == "ToC-Based":
            print("Running ToC-Based Alignment Workflow...")
            
            # --- Step 3/8: Extracting and structuring ToCs ---
            print("Step 3/8: Extracting and structuring Tables of Contents...")
            # Note: toc_page_num from form is 1-indexed, function is 0-indexed
            eng_toc_page_idx = max(0, toc_page_num - 1) 
            english_toc = structure_toc(get_toc_text_from_pdf_bytes(eng_pdf_bytes, page_num=eng_toc_page_idx))
            german_toc = structure_toc(get_toc_text_from_pdf_bytes(ger_pdf_bytes, page_num=eng_toc_page_idx))

            # --- Step 4/8: Aligning ToC sections ---
            print("Step 4/8: Aligning ToC sections...")
            aligned_sections = align_tocs(english_toc, german_toc)
            print(f"Matched {len(aligned_sections)} ToC sections.")

            # --- Step 5/8: Aligning content for each section ---
            print("Step 5/8: Aligning content for each section...")
            section_debug_data = {}
            for i, section in enumerate(aligned_sections):
                eng_sec, ger_sec = section['english'], section['german']
                print(f"  -> Aligning section: '{eng_sec['title']}'")

                eng_section_content = [item for item in full_english_content if eng_sec['start_page'] <= item['page'] <= eng_sec['end_page']]
                ger_section_content = [item for item in full_german_content if ger_sec['start_page'] <= item['page'] <= ger_sec['end_page']]

                if eng_section_content and ger_section_content:
                    aligned_pairs_section = align_content(eng_section_content, ger_section_content, context_window=1)
                    final_aligned_pairs.extend(aligned_pairs_section)
                    section_debug_data[eng_sec['title']] = aligned_pairs_section

            # --- Step 6/8: Saving alignment and debug reports (server-side) ---
            print("Step 6/8: Saving alignment and debug reports...")
            final_aligned_pairs.sort(key=lambda x: (x['english']['page'] if x.get('english') else float('inf')))
            
            alignment_report_path = output_dir / f"alignment_{base_filename}.xlsx"
            save_alignment_report(final_aligned_pairs, alignment_report_path)
            
            debug_report_path = output_dir / f"debug_report_{base_filename}.xlsx"
            save_sectionwise_debug_report(section_debug_data, debug_report_path)

            # --- Step 7/8: Evaluating aligned pairs ---
            print("Step 7/8: Evaluating aligned pairs for errors...")
            evaluation_results = list(run_evaluation_pipeline(final_aligned_pairs))

            # --- Step 8/8: Saving evaluation report (server-side) ---
            print("Step 8/8: Saving evaluation report...")
            if evaluation_results:
                eval_report_path = output_dir / f"evaluation_{base_filename}.xlsx"
                save_evaluation_report(evaluation_results, eval_report_path)

        
        else: # Full Document (Direct)
            print("Running Full Document (Direct) Alignment Workflow...")

            # --- Step 3/5: Performing semantic alignment ---
            print("Step 3/5: Performing semantic alignment...")
            final_aligned_pairs = align_content(
                full_english_content,
                full_german_content,
                context_window=1,
            )
            print(f"Alignment complete. Found {len(final_aligned_pairs)} aligned pairs.")

            # --- Step 4/5: Evaluating aligned pairs ---
            print("Step 4/5: Evaluating aligned pairs for errors...")
            evaluation_results = list(run_evaluation_pipeline(final_aligned_pairs))

            # --- Step 5/5: Saving alignment and evaluation reports (server-side) ---
            print("Step 5/5: Saving alignment and evaluation reports...")
            final_aligned_pairs.sort(key=lambda x: (x['english']['page'] if x.get('english') else float('inf')))
            
            alignment_report_path = output_dir / f"alignment_{base_filename}.xlsx"
            save_alignment_report(final_aligned_pairs, alignment_report_path)
            
            if evaluation_results:
                eval_report_path = output_dir / f"evaluation_{base_filename}.xlsx"
                save_evaluation_report(evaluation_results, eval_report_path)

        # ---
        # --- END: WORKFLOW SPLIT ---
        # ---

        # --- Final Step: Prepare Response for React ---
        print("Analysis complete. Preparing final response...")
        
        # 1. Create the Excel report in memory
        excel_data_bytes = create_excel_report_in_memory(evaluation_results)
        
        # 2. Encode the Excel report as a Base64 string for JSON transport
        report_base64 = base64.b64encode(excel_data_bytes).decode('utf-8')
        
        # 3. Return both the JSON findings and the Base64 report
        return {
            "findings": evaluation_results,
            "report_base64": report_base64,
            "message": "Analysis successful"
        }

    except Exception as e:
        # --- Robust Error Handling ---
        print(f"FATAL: An error occurred during analysis: {e}")
        # Print the full stack trace to the server logs
        traceback.print_exc() 
        
        # Raise a proper HTTP error to send to the React client
        raise HTTPException(
            status_code=500,
            detail=f"An internal server error occurred: {e}"
        )

# --- To run this server ---
# 1. Make sure your venv is active
# 2. In your /backend/ folder, run:
#    uvicorn main:app --reload
