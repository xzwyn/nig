import json
from pathlib import Path
from typing import List, Dict, Any

import config

# A type alias for our structured content for clarity
ContentItem = Dict[str, Any]


# --- FIX 1: Robust table conversion with Markdown sanitization ---
def _convert_table_to_markdown(table_obj: Dict) -> str:
    """Converts an Azure table object into a Markdown string, handling row/col spans."""
    if not table_obj.get('cells'):
        return ""

    row_count = table_obj.get('rowCount', 0)
    col_count = table_obj.get('columnCount', 0)

    if row_count == 0 or col_count == 0:
        return ""

    # A grid to hold the final text content
    grid = [["" for _ in range(col_count)] for _ in range(row_count)]
    # A shadow grid to track occupied cells (due to spans)
    occupied = [[False for _ in range(col_count)] for _ in range(row_count)]

    header_row_indices = set()

    # Sort cells to process top-left ones first, ensuring consistent filling
    cells = sorted(table_obj.get('cells', []), key=lambda x: (x.get('rowIndex', 0), x.get('columnIndex', 0)))

    for cell in cells:
        r = cell.get('rowIndex', 0)
        c = cell.get('columnIndex', 0)

        # Skip anomalous cells outside the defined grid
        if r >= row_count or c >= col_count:
            continue

        # Find the next available column in the current row if this one is occupied
        while c < col_count and occupied[r][c]:
            c += 1

        if c >= col_count:
            continue  # Row is full, this cell is anomalous

        # --- FIX: Sanitize content for Markdown ---
        # Clean content and escape Markdown-breaking pipe characters
        content = cell.get('content', '').strip().replace('\n', ' ').replace('|', '\|')
        # --- END FIX ---
        
        row_span = cell.get('rowSpan', 1)
        col_span = cell.get('columnSpan', 1)

        # Place the content in the grid
        grid[r][c] = content

        # Mark all cells covered by this span as occupied
        for i in range(r, min(r + row_span, row_count)):
            for j in range(c, min(c + col_span, col_count)):
                occupied[i][j] = True

        if cell.get('kind') == 'columnHeader':
            # Mark all rows this header cell spans as part of the header
            for i in range(r, min(r + row_span, row_count)):
                header_row_indices.add(i)

    markdown_str = ""
    separator_generated = False

    # Now, build the markdown string from the grid
    for r_idx in range(row_count):
        row_cells = [grid[r_idx][c_idx] for c_idx in range(col_count)]
        markdown_str += "| " + " | ".join(row_cells) + " |\n"

        # If this was a header row, and we haven't made the separator yet, add it
        if r_idx in header_row_indices and not separator_generated:
            # Check if the *next* row is NOT a header row
            if (r_idx + 1) >= row_count or (r_idx + 1) not in header_row_indices:
                markdown_str += "| " + " | ".join(["---"] * col_count) + " |\n"
                separator_generated = True

    # In case the *only* row was a header row
    if not separator_generated and len(header_row_indices) > 0:
        markdown_str += "| " + " | ".join(["---"] * col_count) + " |\n"

    return markdown_str.strip()
# --- END FIX ---


# --- FIX 2: Intelligent Stitching & Page Number Logic ---
def process_document_json(doc_intelligence_data: Any) -> List[ContentItem]:
    # Allow passing a file path or a preloaded dict
    if isinstance(doc_intelligence_data, (str, Path)):
        with open(Path(doc_intelligence_data), 'r', encoding='utf-8') as f:
            doc_intelligence_data = json.load(f)

    try:
        analyze_result = doc_intelligence_data['analyzeResult']
        full_text_content = analyze_result['content']
        raw_paragraphs = analyze_result.get('paragraphs', [])
        pages = analyze_result.get('pages', [])
        raw_tables = analyze_result.get('tables', [])
    except KeyError as e:
        raise ValueError(f"Document Intelligence data is missing expected key: {e}") from e

    # --- Step 1: Identify all character offsets (No Change) ---
    table_offsets = set()
    for table in raw_tables:
        for span in table.get('spans', []):
            for i in range(span['offset'], span['offset'] + span['length']):
                table_offsets.add(i)

    handwritten_offsets = set()
    if 'styles' in analyze_result:
        for style in analyze_result['styles']:
            if style.get('isHandwritten') and style.get('spans'):
                for span in style['spans']:
                    for i in range(span['offset'], span['offset'] + span['length']):
                        handwritten_offsets.add(i)

    page_lookup = {}
    for page in pages:
        for span in page.get('spans', []):
            for i in range(span['offset'], span['offset'] + span['length']):
                page_lookup[i] = page.get('pageNumber', 0)

    # --- Step 2: Extract all content, including tables, and sort by position (No Change) ---
    all_content: List[ContentItem] = []

    # Process PARAGRAPHS
    for p in raw_paragraphs:
        role = p.get('role', 'paragraph')
        if role in config.IGNORED_ROLES or not p.get('spans'):
            continue

        offset = p['spans'][0]['offset']
        # If the paragraph is inside a table or is handwritten, SKIP it.
        if offset in table_offsets or offset in handwritten_offsets:
            continue

        length = p['spans'][0]['length']
        text = full_text_content[offset : offset + length].strip()
        page_number = page_lookup.get(offset, 0)
        if text:
            all_content.append({'text': text, 'type': role, 'page': page_number, 'offset': offset})

    # Process TABLES
    for table in raw_tables:
        if not table.get('spans'):
            continue
        offset = table['spans'][0]['offset']
        page_number = page_lookup.get(offset, 0)
        # This now calls the fixed function from above
        markdown_table = _convert_table_to_markdown(table)
        if markdown_table:
            all_content.append({'text': markdown_table, 'type': 'table', 'page': page_number, 'offset': offset})

    # Sort all extracted content by its character offset to maintain document order
    all_content.sort(key=lambda x: x['offset'])

    # --- Step 3: Stitch broken paragraphs (INTELLIGENTLY + REQUESTED PAGE LOGIC) ---
    final_content: List[ContentItem] = []
    if not all_content:
        return []

    # Start with the first segment as our initial "stitched" block
    stitched_segment = all_content[0].copy()

    for i in range(1, len(all_content)):
        current_segment = all_content[i]

        # Check if either segment is a "standalone" type that should not be stitched
        is_prev_standalone = stitched_segment['type'] in config.STRUCTURAL_ROLES or stitched_segment['type'] == 'table'
        is_curr_standalone = current_segment['type'] in config.STRUCTURAL_ROLES or current_segment['type'] == 'table'

        # If the current segment is standalone, finalize the previous one and add the current one.
        if is_curr_standalone:
            final_content.append(stitched_segment)  # Add the (potentially stitched) previous block
            stitched_segment = current_segment.copy()  # The new "stitched" block is just this standalone one
            continue

        # If the previous segment was standalone, just start a new block with the current one.
        if is_prev_standalone:
            final_content.append(stitched_segment)  # Add the standalone previous block
            stitched_segment = current_segment.copy()  # Start the new paragraph
            continue

        # --- This is the core logic ---
        # At this point, we know both `stitched_segment` and `current_segment` are 'paragraph' types.
        
        prev_text = stitched_segment['text'].strip()
        curr_text = current_segment['text'].strip()

        if not curr_text:
            continue # Skip empty paragraphs

        # Define our "intelligent" stitching conditions
        prev_ends_with_punctuation = prev_text.endswith(('.', '!', '?', ':', 'â€¢'))
        curr_starts_with_lowercase = curr_text[0].islower()

        # We only stitch if the previous part *doesn't* end a sentence
        # AND the current part *looks like* it's continuing a sentence.
        if not prev_ends_with_punctuation and curr_starts_with_lowercase:
            # Stitch it!
            stitched_segment['text'] += f" {current_segment['text']}"
            
            # --- FIX: Per your request, the page number is NOT updated. ---
            # It will retain the page number of the *start* of the paragraph (item 'A').
        else:
            # Don't stitch. Finalize the previous segment and start a new one.
            final_content.append(stitched_segment)
            stitched_segment = current_segment.copy()


    # Add the last stitched segment
    if stitched_segment:
        final_content.append(stitched_segment)

    return final_content
