// frontend/vite.config.js
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})

// backend/src/alignment/semantic_aligner.py
from typing import List, Dict, Any, Tuple
from pathlib import Path
import numpy as np
from openai import AzureOpenAI
from tqdm import tqdm
import faiss

import config
# Use the central Azure client now
from src.clients.azure_client import _get_embedding_client

# Type Aliases for clarity
ContentItem = Dict[str, Any]
AlignedPair = Dict[str, Any]


def _get_embeddings_in_batches(
    texts: List[str],
    content_items: List[ContentItem],
    client: AzureOpenAI,  # Now accepts the client as an argument
    batch_size: int = 16,
    context_window: int = 0
) -> np.ndarray:
    """
    Generates embeddings by sending texts to the Azure API in batches.
    Optionally includes context from surrounding segments.
    """
    if context_window > 0:
        texts_with_context = []
        for i, text in enumerate(texts):
            pre_context = "".join([f"{content_items[j]['text']} " for j in range(max(0, i - context_window), i)])
            post_context = "".join([f" {content_items[j]['text']}" for j in range(i + 1, min(len(texts), i + context_window + 1))])
            content_type = content_items[i]['type']
            page_num = content_items[i]['page']
            context_text = f"{pre_context}[SEP]{text}[SEP]{post_context} [TYPE:{content_type}] [PAGE:{page_num}]".strip()
            texts_with_context.append(context_text)
        texts_to_embed = texts_with_context
    else:
        texts_to_embed = texts

    all_embeddings = []
    for i in tqdm(range(0, len(texts_to_embed), batch_size), desc="Generating Embeddings"):
        batch = texts_to_embed[i:i + batch_size]
        try:
            response = client.embeddings.create(input=batch, model=config.AZURE_EMBEDDING_DEPLOYMENT_NAME)
            batch_embeddings = [item.embedding for item in response.data]
            all_embeddings.extend(batch_embeddings)

            # --- FIX for Flaw 1 ---
            # Do not silently continue with bad data. Re-raise the exception.
        except Exception as e:
            print(f"FATAL: An error occurred while processing an embedding batch: {e}")
            # This exception will be caught by the main app.py try/except block
            # and displayed to the user.
            raise RuntimeError(f"Failed to generate embeddings: {e}") from e
            # --- END FIX ---

    return np.array(all_embeddings, dtype='float32')


def _score_candidates_vectorized(
    x: np.ndarray,
    y: np.ndarray,
    ind: np.ndarray,
    x_mean: np.ndarray,
    y_mean: np.ndarray
) -> np.ndarray:
    """
    Calculates margin scores for candidates using vectorized NumPy operations for high performance.
    """
    # 1. Use advanced indexing to get the embeddings of all 'k' neighbors
    y_neighbors = y[ind]

    # 2. Calculate dot product (cosine similarity) for all pairs at once using einsum
    cosine_similarities = np.einsum('ik,ijk->ij', x, y_neighbors)

    # 3. Get the mean similarity of the neighbors
    y_mean_neighbors = y_mean[ind]

    # 4. Calculate the average of source and target mean similarities
    avg_mean_sim = (x_mean[:, np.newaxis] + y_mean_neighbors) / 2

    # 5. Calculate the margin score for all candidates. Add epsilon to avoid division by zero.
    margin = lambda a, b: a / b
    scores = margin(cosine_similarities, avg_mean_sim + 1e-9)

    return scores


def _calculate_margin_scores_and_matches(
    source_embeds: np.ndarray,
    target_embeds: np.ndarray,
    k: int = 4
) -> List[Tuple[int, int, float, float]]:
    """
    Calculates alignment scores using the margin method and returns the best 1-to-1 matches.
    Now also returns the original cosine similarity to avoid redundant calculations.
    """
    # 1. Normalize embeddings for cosine similarity
    source_embeds = source_embeds / np.linalg.norm(source_embeds, axis=1, keepdims=True)
    target_embeds = target_embeds / np.linalg.norm(target_embeds, axis=1, keepdims=True)

    # 2. Find k-Nearest Neighbors (kNN) using FAISS
    index_target = faiss.IndexFlatIP(target_embeds.shape[1])
    index_target.add(target_embeds)
    sim_fwd, ind_fwd = index_target.search(source_embeds, k)

    index_source = faiss.IndexFlatIP(source_embeds.shape[1])
    index_source.add(source_embeds)
    sim_bwd, ind_bwd = index_source.search(target_embeds, k)

    # 3. Calculate mean similarities
    mean_fwd_sim = sim_fwd.mean(axis=1)
    mean_bwd_sim = sim_bwd.mean(axis=1)

    # 4. Calculate margin scores using the new vectorized function
    scores_fwd = _score_candidates_vectorized(source_embeds, target_embeds, ind_fwd, mean_fwd_sim, mean_bwd_sim)
    scores_bwd = _score_candidates_vectorized(target_embeds, source_embeds, ind_bwd, mean_bwd_sim, mean_fwd_sim)

    # 5. Find the best matches
    fwd_best_idx = ind_fwd[np.arange(source_embeds.shape[0]), scores_fwd.argmax(axis=1)]
    bwd_best_idx = ind_bwd[np.arange(target_embeds.shape[0]), scores_bwd.argmax(axis=1)]

    # 6. Combine and enforce 1-to-1 mapping
    potential_matches = []
    fwd_scores_max = scores_fwd.max(axis=1)
    fwd_scores_argmax = scores_fwd.argmax(axis=1)

    for i in range(source_embeds.shape[0]):
        cosine_sim = sim_fwd[i, fwd_scores_argmax[i]]
        potential_matches.append((i, fwd_best_idx[i], fwd_scores_max[i], cosine_sim))

    bwd_scores_max = scores_bwd.max(axis=1)
    bwd_scores_argmax = scores_bwd.argmax(axis=1)
    for i in range(target_embeds.shape[0]):
        cosine_sim = sim_bwd[i, bwd_scores_argmax[i]]
        potential_matches.append((bwd_best_idx[i], i, bwd_scores_max[i], cosine_sim))

    potential_matches.sort(key=lambda x: x[2], reverse=True)  # Sort by margin score

    final_matches = []
    seen_source = set()
    seen_target = set()
    for src_idx, trg_idx, margin_score, cos_sim in potential_matches:
        if src_idx not in seen_source and trg_idx not in seen_target:
            final_matches.append((src_idx, trg_idx, margin_score, cos_sim))
            seen_source.add(src_idx)
            seen_target.add(trg_idx)

    return final_matches


def align_content(
    english_content: List[ContentItem],
    german_content: List[ContentItem],
    context_window: int = 0
) -> List[AlignedPair]:
    """
    Aligns content using margin-based scoring, forcing a pair for all possible items.
    """
    if not english_content or not german_content:
        return []

    client = _get_embedding_client()  # Use the central client

    # 1. Get embeddings
    english_embeddings = _get_embeddings_in_batches(
        [item['text'] for item in english_content], english_content, client, context_window=context_window
    )
    german_embeddings = _get_embeddings_in_batches(
        [item['text'] for item in german_content], german_content, client, context_window=context_window
    )

    # 2. Get the best 1-to-1 matches using the new margin-based method
    print("Finding best 1-to-1 matches using margin-based scoring...")
    best_matches = _calculate_margin_scores_and_matches(english_embeddings, german_embeddings)

    # 3. Create the list of aligned pairs
    aligned_pairs: List[AlignedPair] = []
    used_english_indices = set()
    used_german_indices = set()

    for eng_idx, ger_idx, margin_score, cos_sim in best_matches:
        if (cos_sim >= config.SIMILARITY_THRESHOLD and margin_score >= config.MARGIN_SCORE_THRESHOLD):
            aligned_pairs.append({
                "english": english_content[eng_idx],
                "german": german_content[ger_idx],
                "similarity": float(cos_sim),
                "margin_score": float(margin_score)  # Add margin score for debug reports
            })
            used_english_indices.add(eng_idx)
            used_german_indices.add(ger_idx)

    # 4. Add unmatched content
    for i, item in enumerate(english_content):
        if i not in used_english_indices:
            aligned_pairs.append({"english": item, "german": None, "similarity": 0.0, "margin_score": 0.0})

    for i, item in enumerate(german_content):
        if i not in used_german_indices:
            aligned_pairs.append({"english": None, "german": item, "similarity": 0.0, "margin_score": 0.0})

    # 5. Sort the final list by the English document page order
    aligned_pairs.sort(key=lambda x: x['english']['page'] if x.get('english') else float('inf'))

    return aligned_pairs

// backend/src/alignment/toc_aligner.py
from typing import List, Dict, Any
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from scipy.optimize import linear_sum_assignment
from src.clients.azure_client import get_embeddings # Uses the existing Azure client

# Type Aliases
ToCItem = Dict[str, Any]
AlignedToCPair = Dict[str, Any]

def align_tocs(english_toc: List[ToCItem], german_toc: List[ToCItem]) -> List[AlignedToCPair]:
    """
    Aligns Table of Contents sections using Azure OpenAI embeddings and the Hungarian algorithm.
    """
    if not english_toc or not german_toc:
        return []

    eng_titles = [item['title'] for item in english_toc]
    ger_titles = [item['title'] for item in german_toc]

    print("Getting embeddings for ToC titles...")
    english_embeddings = np.array(get_embeddings(eng_titles))
    german_embeddings = np.array(get_embeddings(ger_titles))

    similarity_matrix = cosine_similarity(english_embeddings, german_embeddings)

    # Use the Hungarian algorithm for optimal assignment
    cost_matrix = -similarity_matrix
    row_indices, col_indices = linear_sum_assignment(cost_matrix)

    aligned_sections: List[AlignedToCPair] = []
    print("Matching ToC sections...")
    for eng_idx, ger_idx in zip(row_indices, col_indices):
        score = similarity_matrix[eng_idx, ger_idx]
        # Use a reasonable threshold to filter out poor matches
        if score > 0.5:
            aligned_sections.append({
                'english': english_toc[eng_idx],
                'german': german_toc[ger_idx],
                'similarity': score
            })
    
    aligned_sections.sort(key=lambda x: x['english']['start_page'])
    return aligned_sections

// backend/src/clients/azure_client.py
import os
from typing import List, Dict, Any, Optional
from openai import AzureOpenAI
from dotenv import load_dotenv
load_dotenv()

_chat_client: Optional[AzureOpenAI] = None
_embedding_client: Optional[AzureOpenAI] = None

_cfg = {
    "chat_endpoint": None,
    "chat_api_key": None,
    "chat_api_version": None,
    "chat_deployment": None,
    "embedding_endpoint": None,
    "embedding_api_key": None,
    "embedding_api_version": None,
    "embedding_deployment": None,
}

def _load_env():
    # Chat configuration
    _cfg["chat_endpoint"] = os.getenv("AZURE_OPENAI_ENDPOINT")
    _cfg["chat_api_key"] = os.getenv("AZURE_OPENAI_API_KEY")
    _cfg["chat_api_version"] = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01")
    _cfg["chat_deployment"] = os.getenv("AZURE_OPENAI_DEPLOYMENT")

    # Embedding configuration
    _cfg["embedding_endpoint"] = os.getenv("AZURE_EMBEDDING_ENDPOINT")
    _cfg["embedding_api_key"] = os.getenv("AZURE_EMBEDDING_API_KEY")
    _cfg["embedding_api_version"] = os.getenv("AZURE_API_VERSION", "2024-02-01")
    _cfg["embedding_deployment"] = os.getenv("AZURE_EMBEDDING_DEPLOYMENT_NAME")

def _get_chat_client() -> AzureOpenAI:
    global _chat_client
    if _chat_client is not None:
        return _chat_client

    _load_env()
    if not _cfg["chat_endpoint"] or not _cfg["chat_api_key"] or not _cfg["chat_deployment"]:
        raise RuntimeError(
            "Azure OpenAI chat client is not configured. "
            "Set AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_KEY, and AZURE_OPENAI_DEPLOYMENT in your .env file."
        )

    _chat_client = AzureOpenAI(
        azure_endpoint=_cfg["chat_endpoint"],
        api_key=_cfg["chat_api_key"],
        api_version=_cfg["chat_api_version"],
    )
    return _chat_client

def _get_embedding_client() -> AzureOpenAI:
    global _embedding_client
    if _embedding_client is not None:
        return _embedding_client

    _load_env()
    if not _cfg["embedding_endpoint"] or not _cfg["embedding_api_key"] or not _cfg["embedding_deployment"]:
        raise RuntimeError(
            "Azure OpenAI embedding client is not configured. "
            "Set AZURE_EMBEDDING_ENDPOINT, AZURE_EMBEDDING_API_KEY, and AZURE_EMBEDDING_DEPLOYMENT_NAME in your .env file."
        )

    _embedding_client = AzureOpenAI(
        azure_endpoint=_cfg["embedding_endpoint"],
        api_key=_cfg["embedding_api_key"],
        api_version=_cfg["embedding_api_version"] or _cfg["chat_api_version"],
    )
    return _embedding_client

def chat(messages: List[Dict[str, Any]], temperature: float = 0.1, model: Optional[str] = None) -> str:
    client = _get_chat_client()
    deployment = model or _cfg["chat_deployment"]

    resp = client.chat.completions.create(
        model=deployment,
        messages=messages,
        temperature=temperature,
    )
    return resp.choices[0].message.content or ""

def get_embeddings(texts: List[str], model: Optional[str]=None) -> List[List[float]]:
    client = _get_embedding_client()
    deployment = model or _cfg['embedding_deployment']

    if not deployment:
        raise ValueError("No embedding deployment specified. Please set AZURE_EMBEDDING_DEPLOYMENT_NAME in your .env file.")

    response = client.embeddings.create(
        input=texts,
        model=deployment
    )
    return [item.embedding for item in response.data]

// backend/src/clients/doc_intelligence_client.py
import os
import json
from datetime import datetime
from pathlib import Path

from azure.core.credentials import AzureKeyCredential
from azure.ai.documentintelligence import DocumentIntelligenceClient

import config

def analyze_pdf(pdf_bytes: bytes, original_filename: str) -> dict:
    endpoint = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT")
    key = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_KEY")

    if not endpoint or not key:
        raise ValueError(
            "Azure Document Intelligence credentials are not configured. "
            "Set AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT and AZURE_DOCUMENT_INTELLIGENCE_KEY in your .env file."
        )

    print(f"Connecting to Document Intelligence service for '{original_filename}'...")
    client = DocumentIntelligenceClient(endpoint=endpoint, credential=AzureKeyCredential(key))

    poller = client.begin_analyze_document(model_id="prebuilt-layout", body=pdf_bytes, content_type="application/pdf")
    result = poller.result()
    print("-> Analysis complete.")

    # Robust serialization across SDK versions; wrap with expected top-level key
    try:
        ar_dict = result.as_dict()  # newer SDKs
    except AttributeError:
        try:
            ar_dict = result.to_dict()  # older SDKs
        except AttributeError:
            # Manual fallback
            ar_dict = {
                "content": getattr(result, "content", ""),
                "pages": [p.as_dict() if hasattr(p, "as_dict") else (p.to_dict() if hasattr(p, "to_dict") else {}) for p in getattr(result, "pages", [])],
                "paragraphs": [x.as_dict() if hasattr(x, "as_dict") else (x.to_dict() if hasattr(x, "to_dict") else {}) for x in getattr(result, "paragraphs", [])],
                "tables": [t.as_dict() if hasattr(t, "as_dict") else (t.to_dict() if hasattr(t, "to_dict") else {}) for t in getattr(result, "tables", [])],
                "styles": [s.as_dict() if hasattr(s, "as_dict") else (s.to_dict() if hasattr(s, "to_dict") else {}) for s in getattr(result, "styles", [])],
            }

    result_dict = {"analyzeResult": ar_dict}

    # Save JSON for reference
    output_dir = Path(config.OUTPUT_DIR)
    output_dir.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = Path(original_filename).stem
    output_filename = f"doc_intelligence_{base_name}_{timestamp}.json"
    output_path = output_dir / output_filename

    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result_dict, f, ensure_ascii=False, indent=4)
        print(f"-> Saved Document Intelligence JSON to '{output_path}'")
    except Exception as e:
        print(f"Warning: Could not save JSON output for '{original_filename}'. Reason: {e}")

    return result_dict

// backend/src/evaluation/evaluators.py
import json
from src.clients.azure_client import chat  

def evaluate_translation_pair(eng_text: str, ger_text: str, model_name=None):
    prompt = f"""
## ROLE
You are the Primary Translation Auditor for ENâ†’DE corporate reports.

## TASK
Identify only the two fatal error categories below and output ONE JSON object.

## ERROR TYPES YOU MAY REPORT
1. Mistranslation
   â€¢ Wrong numeric value (digits, words, units, decimals, percentages)
   â€¢ Polarity flip / negation error (e.g., required â†” not required)
   â€¢ Change of actor or agency (who did/decided/informed whom)

2. Omission
   The English text states a concrete count (â€œtwoâ€, â€œthreeâ€, â€œbothâ€, â€œeitherâ€) or lists specific items, and at least one required element is missing in German.

Do not flag: stylistic differences, safe synonyms, acceptable German report titles (â€œNichtfinanzielle ErklÃ¤rungâ€, â€œErklÃ¤rung zur UnternehmensfÃ¼hrungâ€ etc.), benign reordering, or tense/voice changes that preserve actor and meaning.

If no fatal error is found, return error_type "None".

If multiple fatal errors exist, choose the most impactful; if tied, prefer "Mistranslation".

## JSON OUTPUT SCHEMA
json {{ "error_type" : "Mistranslation" | "Omission" | "None", "original_phrase" : "", "translated_phrase": "", "explanation" : "<â‰¤40 words>", "suggestion" : "" }}

## POSITIVE EXAMPLES
1 Â· Mistranslation (number)
EN â€œRevenue increased by 2.3 million.â€
DE â€œDer Umsatz stieg um 2,8 Millionen.â€
â†’ error_type â€œMistranslationâ€, original â€œ2.3 millionâ€, translated â€œ2,8 Millionenâ€

2 Â· Mistranslation (polarity)
EN â€œThe audit is not required.â€
DE â€œDie PrÃ¼fung ist erforderlich.â€
â†’ error_type â€œMistranslationâ€, original â€œnot requiredâ€, translated â€œerforderlichâ€

3 Â· Mistranslation (actor/agency)
EN â€œThe company was notified by the regulator.â€
DE â€œDas Unternehmen informierte die AufsichtsbehÃ¶rde.â€
â†’ error_type â€œMistranslationâ€, original â€œwas notified by the regulatorâ€, translated â€œinformierte die AufsichtsbehÃ¶rdeâ€

4 Â· Omission (enumeration/count)
EN â€œBoth measures will apply: cost cap and hiring freeze.â€
DE â€œEs gilt die Einstellungsstop.â€
â†’ error_type â€œOmissionâ€, original â€œcost capâ€, translated â€œâ€

5 Â· None (acceptable variation)
EN â€œThe report is comprehensive.â€
DE â€œDer Bericht ist umfassend.â€
â†’ error_type â€œNoneâ€

## TEXTS TO AUDIT
<Original English>
{eng_text}
</Original English>

<German Translation>
{ger_text}
</German Translation>

## YOUR RESPONSE
Return the JSON object onlyâ€”no extra text, no markdown.

## NOTES
- Compare all numbers, signs, and units (%, bps, million/Mio., billion/Mrd.).
- Treat passive/active voice as fine unless the responsible actor changes.
- For omissions, ensure every counted or listed element appears in German.
- Keep â€œexplanationâ€ concise; â€œsuggestionâ€ should minimally correct the German (or note the missing item).
"""
    try:
        content = chat(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
            model=model_name,
        ).strip()

        j0, j1 = content.find("{"), content.rfind("}") + 1
        if j0 != -1 and j1 != -1:
            return json.loads(content[j0:j1])
        return {"error_type": "System Error",
                "explanation": "No JSON object in LLM reply."}
    except Exception as exc:
        print(f"evaluate_translation_pair â†’ {exc}")
        return {"error_type": "System Error", "explanation": str(exc)}

def check_context_mismatch(eng_text: str, ger_text: str, model_name: str = None):
    prompt = f"""
ROLE: Narrative-Integrity Analyst

Goal: Decide if the German text tells a **different story** from the
English.  â€œDifferentâ€ means a change in
â€¢ WHO does WHAT to WHOM
â€¢ factual outcome or direction of action
â€¢ polarity (e.g. â€œcomprehensiveâ€ â†” â€œunvollstÃ¤ndigâ€)

Ignore style, word order, or minor re-phrasing.

Respond with JSON:

{{
  "context_match": "Yes" | "No",
  "explanation":  "<one concise sentence>"
}}

Examples
--------
1) Role reversal (should be No)
EN  Further, the committee *was informed* by the Board â€¦
DE  DarÃ¼ber hinaus *leitete der Ausschuss eine Untersuchung ein* â€¦
â†’ roles flipped â‡’ "No"

2) Identical meaning (Yes)
EN  Declaration of Conformity with the German Corporate Governance Code
DE  EntsprechenserklÃ¤rung zum Deutschen Corporate Governance Kodex
â†’ "Yes"

Analyse the following text pair and respond with the JSON only.

<Original_English>
{eng_text}
</Original_English>

<German_Translation>
{ger_text}
</German_Translation>
"""
    try:
        content = chat(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
            model=model_name,
        ).strip()

        j0, j1 = content.find("{"), content.rfind("}") + 1
        return json.loads(content[j0:j1])
    except Exception as exc:
        return {"context_match": "Error", "explanation": str(exc)}

// backend/src/evaluation/pipeline.py
import json
from typing import List, Dict, Any, Optional
from tqdm import tqdm

from src.evaluation.evaluators import evaluate_translation_pair, check_context_mismatch
from src.clients.azure_client import chat

__all__ = ["run_evaluation_pipeline"]

AlignedPair = Dict[str, Any]
EvaluationFinding = Dict[str, Any]

def _agent2_validate_finding(
    eng_text: str,
    ger_text: str,
    error_type: str,
    explanation: str,
    model_name: Optional[str] = None,
):
    """
    Second-stage reviewer.  Confirms only truly fatal errors and rejects
    false positives.
    """
    prompt = f"""
## ROLE
**Senior Quality Reviewer** â€“ you are the final gatekeeper of ENâ†’DE
translation findings.

## TASK
Decide whether the finding delivered by Agent-1 must be *Confirmed* or
*Rejected*.

## INSTRUCTIONS
1. Eligible error_type values are **exactly**:
   â€¢ "Mistranslation"  
   â€¢ "Omission"

2. Confirm only when the evidence is unmistakable:
   â€¢ Mistranslation
       â€“ number mismatch (digit or word)  
       â€“ polarity flip / opposite meaning  
       â€“ actor/role inversion  
   â€¢ Omission
       â€“ English states an explicit count (â€œtwoâ€, â€œthreeâ€, â€œbothâ€ â€¦) **or**
         lists concrete items, and at least one item is *truly* missing in
         German (not conveyed by paraphrase).

3. Reject when:
   â€¢ Difference is stylistic or synonymous.  
   â€¢ Proper names / document titles are rendered with an accepted German
     equivalent (e.g. â€œNichtfinanzielle ErklÃ¤rungâ€).  
   â€¢ Alleged omission is actually present via paraphrase.  

## OUTPUT â€‘ JSON ONLY
json {{ "verdict" : "Confirm" | "Reject", "reasoning": "" }}

## MATERIAL TO REVIEW
English text:
\"\"\"{eng_text}\"\"\"

German text:
\"\"\"{ger_text}\"\"\"

Agent-1 proposed:
  error_type : {error_type}
  explanation: {explanation}

## YOUR RESPONSE
Return the JSON object only â€“ no extra text.
"""
    try:
        content = chat(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
            model=model_name,
        )
        j0, j1 = content.find("{"), content.rfind("}") + 1
        verdict_json = json.loads(content[j0:j1])
        is_confirmed = verdict_json.get("verdict", "").lower() == "confirm"
        reasoning = verdict_json.get("reasoning", "")
        return is_confirmed, reasoning, content.strip()
    except (ValueError, json.JSONDecodeError) as exc:
        print(f"  - Agent-2 JSON parse error: {exc}")
        return False, f"System error: {exc}", "{}"
    except Exception as exc:
        print(f"  - Agent-2 unexpected error: {exc}")
        return False, "System error (non-parsing issue)", "{}"

def run_evaluation_pipeline(aligned_pairs: List[AlignedPair]) -> List[EvaluationFinding]:
    findings = []

    for pair in tqdm(aligned_pairs, desc="Evaluating Pairs"):
        eng_elem = pair.get('english')
        ger_elem = pair.get('german')

        if eng_elem and not ger_elem:
            findings.append({
                "type": f"Omission",
                "english_text": eng_elem['text'],
                "german_text": "---",
                "suggestion": "This content from the English document is missing in the German document.",
                "page": eng_elem['page']
            })
            continue

        if not eng_elem and ger_elem:
            findings.append({
                "type": f"Addition",
                "english_text": "---",
                "german_text": ger_elem['text'],
                "suggestion": "This content from the German document does not appear to have a source in the English document.",
                "page": ger_elem['page']
            })
            continue

        if eng_elem and ger_elem:
            eng_text = eng_elem['text']
            ger_text = ger_elem['text']

            # Agent 1
            finding = evaluate_translation_pair(eng_text, ger_text)
            error_type = finding.get("error_type", "None")

            if error_type not in ["None", "System Error"]:
                # Agent 2
                is_confirmed, reasoning, _ = _agent2_validate_finding(
                    eng_text, ger_text, error_type, finding.get("explanation")
                )

                if is_confirmed:
                    findings.append({
                        "type": error_type,
                        "english_text": eng_text,
                        "german_text": ger_text,
                        "suggestion": finding.get("suggestion"),
                        "page": eng_elem.get('page'),
                        "original_phrase": finding.get("original_phrase"),
                        "translated_phrase": finding.get("translated_phrase")
                    })
                else: # Agent 2 rejected, run Agent 3
                    context_result = check_context_mismatch(eng_text, ger_text)
                    context_match_verdict = context_result.get('context_match', 'Error')
                    if context_match_verdict.lower() == "no":
                        findings.append({
                            "type": "Context Mismatch",
                            "english_text": eng_text,
                            "german_text": ger_text,
                            "suggestion": context_result.get("explanation"),
                            "page": eng_elem.get('page')
                        })

    return findings

// backend/src/processing/json_parser.py
import json
from pathlib import Path
from typing import List, Dict, Any

import config

ContentItem = Dict[str, Any]


def _convert_table_to_markdown(table_obj: Dict) -> str:
    """Converts an Azure table object into a Markdown string, handling row/col spans."""
    if not table_obj.get('cells'):
        return ""

    row_count = table_obj.get('rowCount', 0)
    col_count = table_obj.get('columnCount', 0)

    if row_count == 0 or col_count == 0:
        # Cannot process table without dimensions, return raw content if possible
        spans = table_obj.get('spans', [])
        if spans:
            # This requires access to the full document content, which this function doesn't have.
            # Returning empty is the safest fallback.
            return ""
        return ""

    # A grid to hold the final text content
    grid = [["" for _ in range(col_count)] for _ in range(row_count)]
    # A shadow grid to track occupied cells (due to spans)
    occupied = [[False for _ in range(col_count)] for _ in range(row_count)]

    header_row_indices = set()

    # Sort cells to process top-left ones first, ensuring consistent filling
    cells = sorted(table_obj.get('cells', []), key=lambda x: (x.get('rowIndex', 0), x.get('columnIndex', 0)))

    for cell in cells:
        r = cell.get('rowIndex', 0)
        c = cell.get('columnIndex', 0)

        # Skip anomalous cells outside the defined grid
        if r >= row_count or c >= col_count:
            continue

        # Find the next available column in the current row if this one is occupied
        while c < col_count and occupied[r][c]:
            c += 1

        if c >= col_count:
            continue  # Row is full, this cell is anomalous

        content = cell.get('content', '').strip().replace('\n', ' ')  # Clean content
        row_span = cell.get('rowSpan', 1)
        col_span = cell.get('columnSpan', 1)

        # Place the content in the grid
        grid[r][c] = content

        # Mark all cells covered by this span as occupied
        for i in range(r, min(r + row_span, row_count)):
            for j in range(c, min(c + col_span, col_count)):
                occupied[i][j] = True

        if cell.get('kind') == 'columnHeader':
            # Mark all rows this header cell spans as part of the header
            for i in range(r, min(r + row_span, row_count)):
                header_row_indices.add(i)

    markdown_str = ""
    separator_generated = False

    # Now, build the markdown string from the grid
    for r_idx in range(row_count):
        # Filter out cells that were "occupied" but not the start of a span
        # No, we need all cells for the final grid structure.
        row_cells = [grid[r_idx][c_idx] for c_idx in range(col_count)]
        markdown_str += "| " + " | ".join(row_cells) + " |\n"

        # If this was a header row, and we haven't made the separator yet, add it
        if r_idx in header_row_indices and not separator_generated:
            # Check if the *next* row is NOT a header row
            if (r_idx + 1) >= row_count or (r_idx + 1) not in header_row_indices:
                markdown_str += "| " + " | ".join(["---"] * col_count) + " |\n"
                separator_generated = True

    # In case the *only* row was a header row
    if not separator_generated and len(header_row_indices) > 0:
        markdown_str += "| " + " | ".join(["---"] * col_count) + " |\n"

    return markdown_str.strip()
# --- END FIX ---


def process_document_json(doc_intelligence_data: Any) -> List[ContentItem]:
    # Allow passing a file path or a preloaded dict
    if isinstance(doc_intelligence_data, (str, Path)):
        with open(Path(doc_intelligence_data), 'r', encoding='utf-8') as f:
            doc_intelligence_data = json.load(f)

    try:
        analyze_result = doc_intelligence_data['analyzeResult']
        full_text_content = analyze_result['content']
        raw_paragraphs = analyze_result.get('paragraphs', [])
        pages = analyze_result.get('pages', [])
        raw_tables = analyze_result.get('tables', [])
    except KeyError as e:
        raise ValueError(f"Document Intelligence data is missing expected key: {e}") from e

    # --- Step 1: Identify all character offsets belonging to tables to avoid duplication ---
    table_offsets = set()
    for table in raw_tables:
        for span in table.get('spans', []):
            for i in range(span['offset'], span['offset'] + span['length']):
                table_offsets.add(i)

    # Identify all character offsets that are handwritten
    handwritten_offsets = set()
    if 'styles' in analyze_result:
        for style in analyze_result['styles']:
            if style.get('isHandwritten') and style.get('spans'):
                for span in style['spans']:
                    for i in range(span['offset'], span['offset'] + span['length']):
                        handwritten_offsets.add(i)

    # Create a quick lookup for page number by span offset
    page_lookup = {}
    for page in pages:
        for span in page.get('spans', []):
            for i in range(span['offset'], span['offset'] + span['length']):
                page_lookup[i] = page.get('pageNumber', 0)

    # --- Step 2: Extract all content, including tables, and sort by position ---
    all_content: List[ContentItem] = []

    # Process PARAGRAPHS
    for p in raw_paragraphs:
        role = p.get('role', 'paragraph')
        if role in config.IGNORED_ROLES or not p.get('spans'):
            continue

        offset = p['spans'][0]['offset']
        # If the paragraph is inside a table or is handwritten, SKIP it.
        if offset in table_offsets or offset in handwritten_offsets:
            continue

        length = p['spans'][0]['length']
        text = full_text_content[offset : offset + length].strip()
        page_number = page_lookup.get(offset, 0)
        if text:
            all_content.append({'text': text, 'type': role, 'page': page_number, 'offset': offset})

    # Process TABLES
    for table in raw_tables:
        if not table.get('spans'):
            continue
        offset = table['spans'][0]['offset']
        page_number = page_lookup.get(offset, 0)
        markdown_table = _convert_table_to_markdown(table)
        if markdown_table:
            all_content.append({'text': markdown_table, 'type': 'table', 'page': page_number, 'offset': offset})

    # Sort all extracted content by its character offset to maintain document order
    all_content.sort(key=lambda x: x['offset'])

    # --- Step 3: Stitch broken paragraphs ---
    final_content: List[ContentItem] = []
    stitched_text = ""
    current_page = 0
    current_type = "paragraph"

    for i, segment in enumerate(all_content):
        # If the current element is a table or a structural heading, finalize the previous stitched text.
        is_standalone = segment['type'] in config.STRUCTURAL_ROLES or segment['type'] == 'table'

        if is_standalone:
            if stitched_text:  # Finalize any pending paragraph
                final_content.append({'text': stitched_text, 'type': current_type, 'page': current_page})
                stitched_text = ""
            final_content.append(segment)  # Add the standalone item
            continue

        # This logic handles stitching of regular paragraphs
        if not stitched_text:  # Start a new paragraph
            stitched_text = segment['text']
            current_page = segment['page']
            current_type = segment['type']
        else:
            # If previous text ends with punctuation, start a new paragraph
            if stitched_text.endswith(('.', '!', '?')):
                final_content.append({'text': stitched_text, 'type': current_type, 'page': current_page})
                stitched_text = segment['text']
                current_page = segment['page']
                current_type = segment['type']
            else:  # Continue stitching the current paragraph
                stitched_text += f" {segment['text']}"

    # Add the last stitched paragraph if it exists
    if stitched_text:
        final_content.append({'text': stitched_text, 'type': current_type, 'page': current_page})

    return final_content

// backend/src/processing/toc_parser.py
import re
from pathlib import Path
from typing import List, Dict, Any
import fitz  

# A type alias for a structured ToC item
ToCItem = Dict[str, Any]

def get_toc_text_from_pdf(pdf_path: Path, page_num: int = 1) -> str:
    """Extracts raw text from a specific page of a PDF file."""
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found at: {pdf_path}")

    try:
        with fitz.open(pdf_path) as doc:
            if page_num < len(doc):
                page = doc.load_page(page_num)
                return page.get_text("text")
            else:
                # Fallback to first page if specified page doesn't exist
                print(f"Warning: Page {page_num} not found. Falling back to page 0.")
                page = doc.load_page(0)
                return page.get_text("text")
    except Exception as e:
        raise IOError(f"Error opening or reading PDF file '{pdf_path}': {e}") from e
def get_toc_text_from_pdf_bytes(pdf_bytes: bytes, page_num: int = 1) -> str:
    """Extracts raw text from a specific page of a PDF file in memory."""
    if not pdf_bytes:
        raise ValueError("PDF bytes are empty.")
    
    try:
        # Open PDF from memory stream
        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            if page_num < len(doc):
                page = doc.load_page(page_num)
                return page.get_text("text")
            else:
                # Fallback to first page if specified page doesn't exist
                print(f"Warning: Page {page_num} not found. Falling back to page 0.")
                page = doc.load_page(0)
                return page.get_text("text")
    except Exception as e:
        raise IOError(f"Error opening or reading PDF bytes: {e}") from e
# --- END NEW FUNCTION ---

def structure_toc(toc_text: str) -> List[ToCItem]:
    """
    Parses the raw text of a Table of Contents into a structured list of sections,
    including their titles and start pages.
    """
    # Regex to find lines ending with a number, optionally followed by junk to be stripped.
    # It captures the title and the page number.
    # Example: "2. Supervisory Board Report ......... 4"
    section_pattern = re.compile(r"^(.*?)\s*[.\s]+(\d+)\s*$")
    
    structured_list: List[ToCItem] = []
    lines = toc_text.split('\n')

    for line in lines:
        line = line.strip()
        if not line or len(line) < 3: # Ignore empty or very short lines
            continue
            
        match = section_pattern.match(line)
        if match:
            title, page_number_str = match.groups()
            
            # Further clean the title from leading numbers/bullets
            title = re.sub(r"^\s*([A-D]|\d{1,2}[\.\s])\s*[_]?\s*", "", title).strip()
            
            if title and len(title) > 4:  # Ensure title is meaningful
                structured_list.append({
                    'title': title,
                    'start_page': int(page_number_str)
                })

    if not structured_list:
        return []

    # Sort by start page to ensure correct order
    structured_list.sort(key=lambda x: x['start_page'])

    # Calculate the end_page for each section
    for i in range(len(structured_list) - 1):
        structured_list[i]['end_page'] = structured_list[i+1]['start_page'] - 1

    # Set end_page for the last section to a high number
    structured_list[-1]['end_page'] = 999

    return structured_list

// backend/src/reporting/markdown_writer.py
from pathlib import Path
from typing import List, Dict, Any

ContentItem = Dict[str, Any]

def save_to_markdown(content: List[ContentItem], filepath: Path) -> None:
    with open(filepath, 'w', encoding='utf-8') as f:
        for item in content:
            if item['type'] in {'title', 'sectionHeading', 'subheading'}:
                f.write(f"## {item['text']}\n\n")
            else:
                f.write(f"{item['text']}\n\n")

// backend/src/reporting/excel_writer.py
import io
from pathlib import Path
from typing import List, Dict, Any
import pandas as pd

AlignedPair = Dict[str, Any]
EvaluationFinding = Dict[str, Any]

def save_alignment_report(aligned_data: List[AlignedPair], filepath: Path) -> None:
    """
    Saves the document alignment data to an Excel file.
    Now includes margin_score if it's available in the data.
    """
    if not aligned_data:
        print("Warning: No aligned data to save to Excel.")
        return

    report_data = []
    # Check if margin_score is present in the first pair
    has_margin_score = 'margin_score' in aligned_data[0]

    for pair in aligned_data:
        eng_item = pair.get('english')
        ger_item = pair.get('german')
        row = {
            "English": eng_item.get('text', '') if eng_item else "--- OMITTED ---",
            "German": ger_item.get('text', '') if ger_item else "--- ADDED ---",
            "Similarity": f"{pair.get('similarity', 0.0):.4f}",
            "Type": (eng_item.get('type') if eng_item else ger_item.get('type', 'N/A')),
            "English Page": (eng_item.get('page') if eng_item else 'N/A'),
            "German Page": (ger_item.get('page') if ger_item else 'N/A')
        }
        if has_margin_score:
            row["Margin Score"] = f"{pair.get('margin_score', 0.0):.4f}"
        report_data.append(row)

    df = pd.DataFrame(report_data)
    try:
        df.to_excel(filepath, index=False, engine='openpyxl')
    except Exception as e:
        print(f"Error: Could not write alignment report to '{filepath}'. Reason: {e}")


def save_evaluation_report(evaluation_results: List[EvaluationFinding], filepath: Path) -> None:
    """Saves the AI evaluation findings to a separate Excel report."""
    if not evaluation_results:
        print("No evaluation findings to save.")
        return
    evaluation_results.sort(key=lambda x: x.get('page', 0))
    df = pd.DataFrame(evaluation_results)
    desired_columns = [
        "page", "type", "suggestion", "english_text", "german_text",
        "original_phrase", "translated_phrase"
    ]
    final_columns = [col for col in desired_columns if col in df.columns]
    df = df[final_columns]
    try:
        df.to_excel(filepath, index=False, sheet_name='Evaluation_Findings')
    except Exception as e:
        print(f"Error: Could not write evaluation report to '{filepath}'. Reason: {e}")


def save_sectionwise_debug_report(
    section_data: Dict[str, List[AlignedPair]],
    filepath: Path
) -> None:
    """
    Saves a detailed, multi-sheet Excel debug report with one sheet per ToC section.
    """
    if not section_data:
        print("Warning: No section data provided for the debug report.")
        return

    try:
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            
            # --- FIX: Use a counter for sheet names ---
            sheet_index = 1
            
            for section_title, aligned_pairs in section_data.items():
                
                # Use a safe, unique sheet name
                safe_sheet_name = f"Section_{sheet_index}"
                sheet_index += 1
                
                if not aligned_pairs:
                    continue

                report_data = []
                for pair in aligned_pairs:
                    # (Your existing logic for appending row data)
                    eng_item = pair.get('english')
                    ger_item = pair.get('german')
                    report_data.append({
                        "English Text": eng_item.get('text', '') if eng_item else "--- OMITTED ---",
                        "German Text": ger_item.get('text', '') if ger_item else "--- ADDED ---",
                        "Cosine Similarity": f"{pair.get('similarity', 0.0):.4f}",
                        "Margin Score": f"{pair.get('margin_score', 0.0):.4f}",
                        "Content Type": (eng_item.get('type') if eng_item else ger_item.get('type', 'N/A')),
                        "English Page": (eng_item.get('page') if eng_item else 'N/A'),
                        "German Page": (ger_item.get('page') if ger_item else 'N/A')
                    })
                
                df_section = pd.DataFrame(report_data)
                
                # --- FIX: Write to the new sheet name ---
                df_section.to_excel(writer, sheet_name=safe_sheet_name, index=False, startrow=2)
                
                # --- (Optional but recommended) Add the title back in ---
                try:
                    worksheet = writer.sheets[safe_sheet_name]
                    worksheet['A1'] = f"Section Title: {section_title}"
                except Exception:
                    pass # Failsafe if we can't get the sheet

        print(f"-> Section-wise debug report saved to: {filepath.resolve()}")
    except Exception as e:
        print(f"Error: Could not write section-wise debug report to '{filepath}'. Reason: {e}")

def create_excel_report_in_memory(evaluation_results: List[EvaluationFinding]) -> bytes:
    """
    Creates the evaluation Excel report in memory and returns it as bytes.
    """
    if not evaluation_results:
        return b''

    evaluation_results.sort(key=lambda x: x.get('page', 0))
    df = pd.DataFrame(evaluation_results)
    desired_columns = [
        "page", "type", "suggestion", "english_text", "german_text",
        "original_phrase", "translated_phrase"
    ]
    final_columns = [col for col in desired_columns if col in df.columns]
    df = df[final_columns]

    output_buffer = io.BytesIO()
    with pd.ExcelWriter(output_buffer, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Evaluation_Findings')

    return output_buffer.getvalue()

// backend/app.py
from dotenv import load_dotenv
load_dotenv()

import streamlit as st
from datetime import datetime
import time
from pathlib import Path

# --- Import project modules ---
import config
from src.clients.doc_intelligence_client import analyze_pdf
from src.processing.json_parser import process_document_json
from src.processing.toc_parser import get_toc_text_from_pdf_bytes, structure_toc
from src.alignment.toc_aligner import align_tocs
from src.alignment.semantic_aligner import align_content
from src.evaluation.pipeline import run_evaluation_pipeline
from src.reporting.excel_writer import (
    create_excel_report_in_memory,
    save_alignment_report,
    save_evaluation_report,
    save_sectionwise_debug_report
)
from src.reporting.markdown_writer import save_to_markdown

# --- Page Configuration & UI Functions (unchanged) ---
st.set_page_config(page_title="Translation Evaluator", layout="wide")


def display_results(results_list: list):
    """Renders the list of evaluation findings in the Streamlit UI."""
    if not results_list:
        return
    st.subheader(f"Found {len(results_list)} noteworthy items")
    results_list.sort(key=lambda x: x.get('page', 0))
    for result in results_list:
        error_type = result.get('type', 'Info')
        with st.container(border=True):
            st.markdown(f"**Page:** `{result.get('page', 'N/A')}` | **Type:** `{error_type}`")
            original_phrase, translated_phrase = result.get("original_phrase"), result.get("translated_phrase")
            if original_phrase or translated_phrase:
                st.markdown("##### ğŸ” Error Focus")
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**Original English Phrase:**")
                    st.error(f"'{original_phrase or 'N/A'}'")
                with col2:
                    st.markdown("**Translated German Phrase:**")
                    st.warning(f"'{translated_phrase or 'N/A'}'")
                st.divider()
            st.markdown("##### Full Text Context")
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"> {result['english_text']}")
            with col2:
                st.markdown(f"> {result['german_text']}")
            st.markdown(f"**ğŸ’¡ Suggestion:** {result['suggestion']}")


# --- Main App ---
st.title("ğŸ“š Translation Evaluator")
st.markdown("This tool aligns and evaluates translated PDF documents. Choose your alignment mode in the sidebar.")
st.divider()

if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'evaluation_results' not in st.session_state:
    st.session_state.evaluation_results = []
if 'error_message' not in st.session_state:
    st.session_state.error_message = None

# --- Sidebar for Inputs and Controls ---
with st.sidebar:
    st.header("1. Upload Documents")
    english_pdf = st.file_uploader("Upload English PDF (Source)", type="pdf", key="eng_pdf")
    german_pdf = st.file_uploader("Upload German PDF (Translation)", type="pdf", key="ger_pdf")

    st.header("2. Configure & Run")
    
    # --- NEW: Alignment Mode Selector ---
    alignment_mode = st.radio(
        "Select Alignment Mode",
        ["ToC-Based", "Full Document"],
        key="alignment_mode",
        help="ToC-Based is more accurate for structured reports. Full Document is faster and works for any file."
    )

    toc_page_num = 0  # Default
    if alignment_mode == "ToC-Based":
        toc_page_num = st.number_input("ToC Page Number in PDF", min_value=1, max_value=20, value=2) - 1
    # --- END NEW ---

    if st.button("ğŸš€ Run Analysis", disabled=not (english_pdf and german_pdf), type="primary"):
        st.session_state.analysis_complete = False
        st.session_state.evaluation_results = []
        st.session_state.error_message = None

        output_dir = Path(config.OUTPUT_DIR)
        output_dir.mkdir(exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_filename = f"{Path(english_pdf.name).stem}_{timestamp}"

        try:
            final_aligned_pairs = []

            with st.spinner("Step 1: Analyzing PDFs with Azure Document Intelligence..."):
                eng_pdf_bytes = english_pdf.getvalue()
                ger_pdf_bytes = german_pdf.getvalue()
                eng_json_data = analyze_pdf(eng_pdf_bytes, english_pdf.name)
                ger_json_data = analyze_pdf(ger_pdf_bytes, german_pdf.name)

            with st.spinner("Step 2: Processing full document content..."):
                full_english_content = process_document_json(eng_json_data)
                full_german_content = process_document_json(ger_json_data)
                st.toast(f"Extracted {len(full_english_content)} EN segments and {len(full_german_content)} DE segments.")

            
            # --- START: WORKFLOW SPLIT ---
            if alignment_mode == "ToC-Based":
                st.info("Running ToC-Based Alignment...")
                section_debug_data = {} # To store data for the debug report

                with st.spinner("Step 3/8: Extracting and structuring Tables of Contents..."):
                    english_toc = structure_toc(get_toc_text_from_pdf_bytes(eng_pdf_bytes, page_num=toc_page_num))
                    german_toc = structure_toc(get_toc_text_from_pdf_bytes(ger_pdf_bytes, page_num=toc_page_num))

                with st.spinner("Step 4/8: Aligning ToC sections..."):
                    aligned_sections = align_tocs(english_toc, german_toc)
                    st.toast(f"Matched {len(aligned_sections)} ToC sections.")
                    with st.expander("âœ… Matched Sections", expanded=True):
                        for sec in aligned_sections:
                            st.write(f"'{sec['english']['title']}' â†’ '{sec['german']['title']}'")

                with st.spinner("Step 5/8: Aligning content for each section..."):
                    progress_bar = st.progress(0, "Aligning sections...")
                    for i, section in enumerate(aligned_sections):
                        eng_sec, ger_sec = section['english'], section['german']

                        eng_section_content = [item for item in full_english_content if eng_sec['start_page'] <= item['page'] <= eng_sec['end_page']]
                        ger_section_content = [item for item in full_german_content if ger_sec['start_page'] <= item['page'] <= ger_sec['end_page']]

                        if eng_section_content and ger_section_content:
                            aligned_pairs_section = align_content(eng_section_content, ger_section_content, context_window=1)
                            final_aligned_pairs.extend(aligned_pairs_section)
                            # Store results for debug report
                            section_debug_data[eng_sec['title']] = aligned_pairs_section

                        progress_bar.progress((i + 1) / len(aligned_sections), f"Aligned '{eng_sec['title']}'")

                with st.spinner("Step 6/8: Saving alignment and debug reports..."):
                    final_aligned_pairs.sort(key=lambda x: (x['english']['page'] if x.get('english') else float('inf')))

                    alignment_report_path = output_dir / f"alignment_{base_filename}.xlsx"
                    save_alignment_report(final_aligned_pairs, alignment_report_path)
                    st.toast("Saved Main Alignment Report.")

                    debug_report_path = output_dir / f"debug_report_{base_filename}.xlsx"
                    save_sectionwise_debug_report(section_debug_data, debug_report_path)
                    st.toast("Saved Section-wise Debug Report.")

                with st.spinner("Step 7/8: Evaluating aligned pairs for errors..."):
                    st.session_state.evaluation_results = list(run_evaluation_pipeline(final_aligned_pairs))

                with st.spinner("Step 8/8: Saving evaluation report..."):
                    if st.session_state.evaluation_results:
                        eval_report_path = output_dir / f"evaluation_{base_filename}.xlsx"
                        save_evaluation_report(st.session_state.evaluation_results, eval_report_path)
                        st.toast("Saved Evaluation Report.")

            else: # Full Document (Direct)
                st.info("Running Full Document (Direct) Alignment...")

                with st.spinner("Step 3/5: Performing semantic alignment..."):
                    final_aligned_pairs = align_content(
                        full_english_content,
                        full_german_content,
                        context_window=1,
                    )
                    st.toast(f"Alignment complete. Found {len(final_aligned_pairs)} aligned pairs.")

                with st.spinner("Step 4/5: Evaluating aligned pairs for errors..."):
                    st.session_state.evaluation_results = list(run_evaluation_pipeline(final_aligned_pairs))

                with st.spinner("Step 5/5: Saving alignment and evaluation reports..."):
                    final_aligned_pairs.sort(key=lambda x: (x['english']['page'] if x.get('english') else float('inf')))
                    
                    alignment_report_path = output_dir / f"alignment_{base_filename}.xlsx"
                    save_alignment_report(final_aligned_pairs, alignment_report_path)
                    st.toast("Saved Main Alignment Report.")
                    
                    if st.session_state.evaluation_results:
                        eval_report_path = output_dir / f"evaluation_{base_filename}.xlsx"
                        save_evaluation_report(st.session_state.evaluation_results, eval_report_path)
                        st.toast("Saved Evaluation Report.")
            
            # --- END: WORKFLOW SPLIT ---

            st.session_state.analysis_complete = True
            st.success("Analysis pipeline finished successfully!")
            time.sleep(2)
            st.rerun()

        except Exception as e:
            # This block will catch errors from either workflow
            st.session_state.error_message = f"An error occurred: {e}"
            st.exception(e) # Also show traceback in the terminal for debugging
            st.rerun()
    
    # --- Download Button ---
    st.header("3. Export Results")
    if st.session_state.analysis_complete and st.session_state.evaluation_results:
        excel_data = create_excel_report_in_memory(st.session_state.evaluation_results)
        st.download_button(
            label="ğŸ“¥ Download Evaluation Report",
            data=excel_data,
            file_name=f"Translation_Evaluation_{datetime.now().strftime('%Y-%m-%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
    else:
        st.markdown("_Report available after analysis._")

# --- Main Display Area ---
st.header("Evaluation Results")

if st.session_state.error_message:
    st.error(st.session_state.error_message, icon="ğŸš¨")
elif st.session_state.analysis_complete:
    if not st.session_state.evaluation_results:
        st.success("âœ… Analysis complete. No significant errors were found.")
    else:
        display_results(st.session_state.evaluation_results)
else:
    st.info("Upload your PDFs, select an alignment mode, and click 'Run Analysis' to begin.")

// backend/config.py
import os
from dotenv import load_dotenv

load_dotenv()

AZURE_EMBEDDING_ENDPOINT = os.getenv("AZURE_EMBEDDING_ENDPOINT")
AZURE_EMBEDDING_API_KEY = os.getenv("AZURE_EMBEDDING_API_KEY")
AZURE_EMBEDDING_DEPLOYMENT_NAME = os.getenv("AZURE_EMBEDDING_DEPLOYMENT_NAME")
AZURE_API_VERSION = os.getenv("AZURE_API_VERSION", "2024-02-01")

IGNORED_ROLES = {'pageHeader', 'pageFooter', 'pageNumber'}
STRUCTURAL_ROLES = {'title', 'sectionHeading'}

W_SEMANTIC = 1  # Weight for semantic similarity (cosine score)
W_TYPE = 0      # Weight for matching content types (e.g., table vs. table)
W_PROXIMITY = 0 # Weight for relative position in the document

TYPE_MATCH_BONUS = 0.1
TYPE_MISMATCH_PENALTY = -0.2

SIMILARITY_THRESHOLD = -1.0

MARGIN_SCORE_THRESHOLD = -1.0


INPUT_DIR: str = "input"
OUTPUT_DIR: str = "output"

// backend/main.py
# --- FastAPI & Standard Lib Imports ---
import io
import base64
import traceback
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

# --- Import your project modules ---
import config
from src.clients.doc_intelligence_client import analyze_pdf
from src.processing.json_parser import process_document_json
from src.processing.toc_parser import get_toc_text_from_pdf_bytes, structure_toc
from src.alignment.toc_aligner import align_tocs
from src.alignment.semantic_aligner import align_content
from src.evaluation.pipeline import run_evaluation_pipeline
from src.reporting.excel_writer import (
    create_excel_report_in_memory,
    save_alignment_report,
    save_evaluation_report,
    save_sectionwise_debug_report
)

# --- FastAPI App Initialization ---
app = FastAPI(
    title="Translation Evaluator API",
    description="Analyzes and evaluates translated PDF documents."
)

# --- CORS Configuration (CRITICAL) ---
# This allows your React frontend (running on localhost:5173) 
# to communicate with this backend (running on localhost:8000).
origins = [
    "http://localhost:5173",  # Default Vite port
    "http://localhost:3000",  # Default Create React App port
    "http://localhost",
    "http://127.0.0.1",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods (GET, POST, etc.)
    allow_headers=["*"],  # Allows all headers
)


# --- Health Check Endpoint ---
@app.get("/", tags=["Status"])
async def root():
    """A simple health check endpoint."""
    return {"message": "Translation Evaluator API is running"}


# --- Main Analysis Endpoint ---
@app.post("/analyze", tags=["Analysis"])
async def analyze_documents(
    english_pdf: UploadFile = File(..., description="The source English PDF file"),
    german_pdf: UploadFile = File(..., description="The translated German PDF file"),
    alignment_mode: str = Form(..., description="Either 'ToC-Based' or 'Full Document'"),
    toc_page_num: int = Form(1, description="The page number of the ToC (1-indexed)")
):
    """
    Analyzes, aligns, and evaluates two PDF documents.
    
    This single endpoint replicates the entire Streamlit workflow.
    """
    
    output_dir = Path(config.OUTPUT_DIR)
    output_dir.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_filename = f"{Path(english_pdf.filename).stem}_{timestamp}"

    try:
        # --- Read file bytes from the upload ---
        print("Reading uploaded PDF bytes...")
        eng_pdf_bytes = await english_pdf.read()
        ger_pdf_bytes = await german_pdf.read()

        # Local variable to store results, replacing st.session_state
        evaluation_results: List[Dict[str, Any]] = []
        final_aligned_pairs: List[Dict[str, Any]] = []

        # --- Step 1: Azure Document Intelligence ---
        print("Step 1: Analyzing PDFs with Azure Document Intelligence...")
        eng_json_data = analyze_pdf(eng_pdf_bytes, english_pdf.filename)
        ger_json_data = analyze_pdf(ger_pdf_bytes, german_pdf.filename)

        # --- Step 2: Processing full document content ---
        print("Step 2: Processing full document content...")
        full_english_content = process_document_json(eng_json_data)
        full_german_content = process_document_json(ger_json_data)
        print(f"Extracted {len(full_english_content)} EN segments and {len(full_german_content)} DE segments.")

        # ---
        # --- START: WORKFLOW SPLIT ---
        # ---
        
        if alignment_mode == "ToC-Based":
            print("Running ToC-Based Alignment Workflow...")
            
            # --- Step 3/8: Extracting and structuring ToCs ---
            print("Step 3/8: Extracting and structuring Tables of Contents...")
            # Note: toc_page_num from form is 1-indexed, function is 0-indexed
            eng_toc_page_idx = max(0, toc_page_num - 1) 
            english_toc = structure_toc(get_toc_text_from_pdf_bytes(eng_pdf_bytes, page_num=eng_toc_page_idx))
            german_toc = structure_toc(get_toc_text_from_pdf_bytes(ger_pdf_bytes, page_num=eng_toc_page_idx))

            # --- Step 4/8: Aligning ToC sections ---
            print("Step 4/8: Aligning ToC sections...")
            aligned_sections = align_tocs(english_toc, german_toc)
            print(f"Matched {len(aligned_sections)} ToC sections.")

            # --- Step 5/8: Aligning content for each section ---
            print("Step 5/8: Aligning content for each section...")
            section_debug_data = {}
            for i, section in enumerate(aligned_sections):
                eng_sec, ger_sec = section['english'], section['german']
                print(f"  -> Aligning section: '{eng_sec['title']}'")

                eng_section_content = [item for item in full_english_content if eng_sec['start_page'] <= item['page'] <= eng_sec['end_page']]
                ger_section_content = [item for item in full_german_content if ger_sec['start_page'] <= item['page'] <= ger_sec['end_page']]

                if eng_section_content and ger_section_content:
                    aligned_pairs_section = align_content(eng_section_content, ger_section_content, context_window=1)
                    final_aligned_pairs.extend(aligned_pairs_section)
                    section_debug_data[eng_sec['title']] = aligned_pairs_section

            # --- Step 6/8: Saving alignment and debug reports (server-side) ---
            print("Step 6/8: Saving alignment and debug reports...")
            final_aligned_pairs.sort(key=lambda x: (x['english']['page'] if x.get('english') else float('inf')))
            
            alignment_report_path = output_dir / f"alignment_{base_filename}.xlsx"
            save_alignment_report(final_aligned_pairs, alignment_report_path)
            
            debug_report_path = output_dir / f"debug_report_{base_filename}.xlsx"
            save_sectionwise_debug_report(section_debug_data, debug_report_path)

            # --- Step 7/8: Evaluating aligned pairs ---
            print("Step 7/8: Evaluating aligned pairs for errors...")
            evaluation_results = list(run_evaluation_pipeline(final_aligned_pairs))

            # --- Step 8/8: Saving evaluation report (server-side) ---
            print("Step 8/8: Saving evaluation report...")
            if evaluation_results:
                eval_report_path = output_dir / f"evaluation_{base_filename}.xlsx"
                save_evaluation_report(evaluation_results, eval_report_path)

        
        else: # Full Document (Direct)
            print("Running Full Document (Direct) Alignment Workflow...")

            # --- Step 3/5: Performing semantic alignment ---
            print("Step 3/5: Performing semantic alignment...")
            final_aligned_pairs = align_content(
                full_english_content,
                full_german_content,
                context_window=1,
            )
            print(f"Alignment complete. Found {len(final_aligned_pairs)} aligned pairs.")

            # --- Step 4/5: Evaluating aligned pairs ---
            print("Step 4/5: Evaluating aligned pairs for errors...")
            evaluation_results = list(run_evaluation_pipeline(final_aligned_pairs))

            # --- Step 5/5: Saving alignment and evaluation reports (server-side) ---
            print("Step 5/5: Saving alignment and evaluation reports...")
            final_aligned_pairs.sort(key=lambda x: (x['english']['page'] if x.get('english') else float('inf')))
            
            alignment_report_path = output_dir / f"alignment_{base_filename}.xlsx"
            save_alignment_report(final_aligned_pairs, alignment_report_path)
            
            if evaluation_results:
                eval_report_path = output_dir / f"evaluation_{base_filename}.xlsx"
                save_evaluation_report(evaluation_results, eval_report_path)

        # ---
        # --- END: WORKFLOW SPLIT ---
        # ---

        # --- Final Step: Prepare Response for React ---
        print("Analysis complete. Preparing final response...")
        
        # 1. Create the Excel report in memory
        excel_data_bytes = create_excel_report_in_memory(evaluation_results)
        
        # 2. Encode the Excel report as a Base64 string for JSON transport
        report_base64 = base64.b64encode(excel_data_bytes).decode('utf-8')
        
        # 3. Return both the JSON findings and the Base64 report
        return {
            "findings": evaluation_results,
            "report_base64": report_base64,
            "message": "Analysis successful"
        }

    except Exception as e:
        # --- Robust Error Handling ---
        print(f"FATAL: An error occurred during analysis: {e}")
        # Print the full stack trace to the server logs
        traceback.print_exc() 
        
        # Raise a proper HTTP error to send to the React client
        raise HTTPException(
            status_code=500,
            detail=f"An internal server error occurred: {e}"
        )

# --- To run this server ---
# 1. Make sure your venv is active
# 2. In your /backend/ folder, run:
#    uvicorn main:app --reload

// backend/requirements.txt
fastapi
uvicorn[standard]
python-multipart
openai
azure-core
python-dotenv
azure-ai-documentintelligence
faiss-cpu
PyMuPDF
numpy
scikit-learn
tqdm
scipy
pandas
openpyxl

// frontend/src/App.css
/* ---
   Modern Dark/Glassmorphism Theme
   --- */

/* --- 1. Root Variables & Base Setup --- */
:root {
  /* Colors */
  --bg-color: #0d1117; /* Dark background (GitHub Dark) */
  --panel-bg: rgba(22, 27, 34, 0.6); /* Glassmorphic panel bg */
  --panel-border: rgba(255, 255, 255, 0.1);
  --text-color: #c9d1d9; /* Light text */
  --text-dim: #8b949e; /* Dimmer text */
  --primary-color: #8884d8; /* Vibrant purple */
  --primary-hover: #9e9bdc;
  --secondary-color: #ffffff; /* Turquoise */
  --secondary-hover: #ffffff;
  --error-color: #f85149;
  --warning-color: #f0ad4e;
  --success-color: #ffffff;
  
  /* Sizing & Effects */
  --border-radius: 12px;
  --panel-padding: 24px;
  --backdrop-blur: 10px; /* The glass effect */
  --shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.37);
  
  /* Font */
  font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

body {
  margin: 0;
  background-color: var(--bg-color);
  background-image: linear-gradient(180deg, rgba(22, 27, 34, 0.1) 0%, var(--bg-color) 100%);
  color: var(--text-color);
  min-height: 100vh;
}

/* --- 2. Main Layout & Header --- */
.app-container {
  width: 100%;
  max-width: 1600px;
  margin: 0 auto;
  padding: 0 1.5rem 2rem;
  box-sizing: border-box;
}

.app-header {
  padding: 1.5rem 0;
  display: flex;
  align-items: center;
  justify-content: center;
  border-bottom: 1px solid var(--panel-border);
  margin-bottom: 2rem;
}

.app-header h1 {
  font-size: 1.75rem;
  font-weight: 600;
  color: #fff;
  display: flex;
  align-items: center;
  gap: 0.75rem;
  margin: 0;
}

.header-icon {
  font-size: 2rem;
  color: var(--primary-color);
}

.app-main {
  /* This is the main change: We only define the gap now. */
  /* The side-by-side grid-template-columns is REMOVED. */
  display: grid;
  grid-template-columns: 1fr;
  gap: 2rem;
}

/* --- 3. Glass Panel Base Style --- */
.glass-panel {
  background: var(--panel-bg);
  border-radius: var(--border-radius);
  border: 1px solid var(--panel-border);
  backdrop-filter: blur(var(--backdrop-blur));
  -webkit-backdrop-filter: blur(var(--backdrop-blur));
  box-shadow: var(--shadow);
  padding: var(--panel-padding);
}

/* --- 4. Control Panel --- */
.control-panel {
  display: flex;
  flex-direction: column;
  gap: 1.5rem;
  height: min-content; /* Panel only as tall as its content */
}

.panel-header {
  font-size: 1.25rem;
  font-weight: 500;
  color: #fff;
  display: flex;
  align-items: center;
  gap: 0.75rem;
  margin: 0 0 1.5rem 0;
  padding-bottom: 0.75rem;
  border-bottom: 1px solid var(--panel-border);
}

.upload-zones, .config-grid, .run-buttons {
  display: grid;
  grid-template-columns: 1fr;
  gap: 1.5rem;
}

/* --- 5. File Upload Zone --- */
.file-drop-zone {
  border-radius: var(--border-radius);
  border: 2px dashed var(--panel-border);
  padding: 1.5rem;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  text-align: center;
  cursor: pointer;
  transition: all 0.3s ease;
  min-height: 120px;
}

.file-drop-zone.dragging,
.file-drop-zone:hover {
  border-color: var(--primary-color);
  background-color: rgba(136, 132, 216, 0.1);
}

.hidden-file-input { display: none; }
.upload-icon { font-size: 2rem; color: var(--primary-color); }
.upload-title { font-weight: 600; color: #fff; margin-top: 0.5rem; }
.upload-text { font-size: 0.9rem; color: var(--text-dim); }

.file-selected {
  flex-direction: row;
  justify-content: space-between;
  border-style: solid;
  border-color: var(--success-color);
  background-color: rgba(48, 213, 200, 0.05);
  padding: 1rem 1.5rem;
  min-height: auto;
}
.file-icon { font-size: 1.5rem; color: var(--success-color); }
.file-name {
  font-weight: 500;
  font-size: 0.95rem;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  max-width: 200px;
}
.remove-file-btn {
  background: transparent;
  border: none;
  color: var(--error-color);
  font-size: 1.25rem;
  cursor: pointer;
  padding: 0;
  display: flex;
}

/* --- 6. Config Section --- */
.form-group {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}
.form-group label {
  font-size: 0.9rem;
  font-weight: 500;
  color: var(--text-dim);
}
.form-group input {
  background: var(--bg-color);
  border: 1px solid var(--panel-border);
  border-radius: 8px;
  padding: 0.75rem 1rem;
  color: var(--text-color);
  font-size: 1rem;
  transition: border-color 0.3s, box-shadow 0.3s;
}
.form-group input:focus {
  outline: none;
  border-color: var(--primary-color);
  box-shadow: 0 0 0 3px rgba(136, 132, 216, 0.3);
}

/* --- Segmented Control --- */
.form-group.segment-group,
.form-group.toc-group {
  /* Make these elements span the full grid width */
  grid-column: 1 / -1; 
}

.segmented-control {
  display: flex;
  width: 100%;
  background: var(--bg-color);
  border-radius: 8px;
  border: 1px solid var(--panel-border);
  padding: 4px;
  box-sizing: border-box;
}
.segment-option {
  flex: 1; /* Each option takes equal space */
  padding: 0.6rem 0.5rem;
  border: none;
  background: transparent;
  color: var(--text-dim);
  font-size: 0.9rem;
  font-weight: 600;
  border-radius: 6px; /* Slightly smaller radius than container */
  cursor: pointer;
  text-align: center;
  transition: all 0.3s ease;
}
.segment-option.active {
  background-color: var(--primary-color);
  color: #fff;
  box-shadow: 0 2px 8px rgba(136, 132, 216, 0.3);
}
.segment-option:not(.active):hover {
  background-color: rgba(255, 255, 255, 0.05);
  color: var(--text-color);
}
/* --- End Segmented Control --- */


/* --- 7. Run Section & Buttons --- */
.btn {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 0.75rem;
  padding: 0.8rem 1.5rem;
  font-size: 1rem;
  font-weight: 600;
  border: none;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.3s ease;
}
.btn-primary {
  background-color: var(--primary-color);
  color: #fff;
  border: 1px solid var(--primary-color);
}
.btn-primary:hover:not(:disabled) {
  background-color: var(--primary-hover);
  border-color: var(--primary-hover);
  box-shadow: 0 0 15px rgba(136, 132, 216, 0.5);
}
.btn-secondary {
  background-color: transparent;
  color: var(--secondary-color);
  border: 1px solid var(--secondary-color);
}
.btn-secondary:hover:not(:disabled) {
  background-color: rgba(48, 213, 200, 0.1);
  box-shadow: 0 0 15px rgba(48, 213, 200, 0.5);
}
.btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

/* --- 8. Results Panel --- */
.results-panel .panel-header {
  margin: 0 0 1.5rem 0;
  padding-bottom: 0;
  border: none;
}
.results-content {
  min-height: 300px;
}

/* --- 9. Status Display --- */
.status-display {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  text-align: center;
  padding: 3rem 1rem;
  min-height: 250px;
  color: var(--text-dim);
}
.status-display .status-icon {
  font-size: 3rem;
  margin-bottom: 1rem;
}
.status-display h3 {
  font-size: 1.25rem;
  color: #fff;
  margin: 0.5rem 0;
}
.status-display.loading { color: var(--primary-color); }
.status-display.error { color: var(--error-color); }
.status-display.error h3 { color: var(--error-color); }
.status-display.empty { color: var(--text-dim); } /* Changed to neutral dim */
.status-display.empty h3 { color: var(--text-dim); }

/* --- NEW SUCCESS STYLE --- */
.status-display.success { color: var(--success-color); }
.status-display.success h3 { color: var(--success-color); }
/* --- End New Style --- */

.loading-status-text {
  font-size: 0.95rem;
  color: var(--text-dim);
  margin-top: 1rem;
  min-height: 1.2em; /* Reserve space to prevent layout jump */
}


/* --- 10. Findings List & Card --- */
.findings-list {
  display: flex;
  flex-direction: column;
  gap: 1.5rem;
}

.finding-card {
  padding: 0; /* Let sections handle padding */
  border-color: rgba(255, 255, 255, 0.05);
}

.card-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 1rem var(--panel-padding);
  border-bottom: 1px solid var(--panel-border);
}

.card-badge {
  padding: 0.25rem 0.75rem;
  border-radius: 20px;
  font-size: 0.85rem;
  font-weight: 600;
  background-color: var(--primary-color);
  color: #fff;
}
/* Badge color overrides */
.card-badge.mistranslation { background-color: var(--error-color); }
.card-badge.omission { background-color: var(--warning-color); color: #000; }
.card-badge.addition { background-color: var(--warning-color); color: #000; }
.card-badge.context-mismatch { background-color: #ff8c00; } /* Dark Orange */

.card-page {
  font-size: 0.9rem;
  font-weight: 500;
  color: var(--text-dim);
}

.card-section {
  padding: 1.5rem var(--panel-padding);
}
.card-section h4 {
  font-size: 1rem;
  font-weight: 600;
  color: var(--text-dim);
  margin: 0 0 1rem 0;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.text-pair {
  display: grid;
  grid-template-columns: 1fr;
  gap: 1rem;
}
.text-block {
  background: rgba(0, 0, 0, 0.2);
  border-radius: var(--border-radius);
  padding: 1rem;
}
.text-block strong {
  display: block;
  margin-bottom: 0.5rem;
  color: #fff;
  font-weight: 500;
}
.text-block blockquote, .text-block p {
  margin: 0;
  color: var(--text-color);
  font-style: italic;
  font-size: 0.95rem;
}

.highlight-en {
  color: #ffb8b8; /* Light red */
  background: rgba(248, 81, 73, 0.1);
  padding: 2px 4px;
  border-radius: 4px;
  font-style: normal !important;
}
.highlight-de {
  color: #fffb8b; /* Light yellow */
  background: rgba(240, 173, 78, 0.1);
  padding: 2px 4px;
  border-radius: 4px;
  font-style: normal !important;
}

.suggestion-section {
  background: rgba(48, 213, 200, 0.05);
  border-top: 1px solid var(--panel-border);
}
.suggestion-section strong {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  color: var(--secondary-color);
  font-size: 1rem;
  font-weight: 600;
}
.suggestion-section p {
  margin: 0.5rem 0 0 0;
  color: var(--text-color);
  font-size: 1rem;
}

/* --- 11. Responsive Design --- */
@media (min-width: 768px) {
  .upload-zones, .config-grid {
    grid-template-columns: 1fr 1fr;
  }
  .run-buttons {
    grid-template-columns: auto auto 1fr;
    justify-content: flex-start;
  }
  .text-pair {
    grid-template-columns: 1fr 1fr;
  }
}

/* Removed the 1200px media query that forced a side-by-side layout.
  The layout is now fully top-down. 
*/

// frontend/src/App.jsx
import { useState } from 'react';
import axios from 'axios'; // We go back to using axios
import { RingLoader } from 'react-spinners';
import { 
  FiFile, FiUploadCloud, FiX, FiCheckCircle, FiAlertTriangle, 
  FiDownload, FiCpu, FiSettings, FiFileText, FiZap 
} from 'react-icons/fi';
import './App.css';

const API_URL = 'http://localhost:8000';

function App() {
  // --- State for the Form ---
  const [englishFile, setEnglishFile] = useState(null);
  const [germanFile, setGermanFile] = useState(null);
  const [alignmentMode, setAlignmentMode] = useState('Full Document');
  const [tocPageNum, setTocPageNum] = useState(2);

  // --- State for the App Status ---
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState(null);
  const [analysisComplete, setAnalysisComplete] = useState(false); // For the success message

  // --- State for the Results ---
  const [findings, setFindings] = useState([]);
  const [reportBase64, setReportBase64] = useState(null);

  /**
   * Main function to handle the API call
   */
  const handleSubmit = async (e) => {
    e.preventDefault();
    if (!englishFile || !germanFile) {
      setError('Please upload both PDF files.');
      return;
    }
    
    // --- RESET ALL STATES ---
    setIsLoading(true);
    setError(null);
    setFindings([]);
    setReportBase64(null);
    setAnalysisComplete(false);

    // --- Prepare Form Data ---
    const formData = new FormData();
    formData.append('english_pdf', englishFile);
    formData.append('german_pdf', germanFile);
    formData.append('alignment_mode', alignmentMode);
    formData.append('toc_page_num', tocPageNum);

    try {
      // --- Use Axios for a simple POST request ---
      const response = await axios.post(`${API_URL}/analyze`, formData, {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      });
      
      // --- Set results from the single response ---
      setFindings(response.data.findings || []);
      setReportBase64(response.data.report_base64);

    } catch (err) {
      const errorMsg = err.response?.data?.detail || err.message;
      setError(`Analysis Failed: ${errorMsg}`);
    } finally {
      // --- Mark loading as false and analysis as complete ---
      setIsLoading(false);
      setAnalysisComplete(true);
    }
  };

  /**
   * Triggers a download of the Base64 Excel data
   */
  const handleDownload = () => {
    if (!reportBase64) return;
    const link = document.createElement('a');
    link.href = `data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,${reportBase64}`;
    link.download = `Translation_Evaluation_${new Date().toISOString().split('T')[0]}.xlsx`;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
  };

  return (
    <div className="app-container">
      <header className="app-header">
        <h1><FiCpu className="header-icon" /> Translation Evaluator</h1>
      </header>

      <main className="app-main">
        {/* --- Form and Controls Panel --- */}
        <form onSubmit={handleSubmit} className="control-panel glass-panel">
          
          <div className="panel-section upload-section">
            <h2 className="panel-header">
              <FiUploadCloud /> 1. Upload Documents
            </h2>
            <div className="upload-zones">
              <FileUploadZone
                file={englishFile}
                setFile={setEnglishFile}
                title="English (Source) PDF"
              />
              <FileUploadZone
                file={germanFile}
                setFile={setGermanFile}
                title="German (Translated) PDF"
              />
            </div>
          </div>

          <div className="panel-section config-section">
            <h2 className="panel-header">
              <FiSettings /> 2. Configure 
            </h2>
            <div className="config-grid">
              <div className="form-group segment-group">
                <label>Alignment Mode</label>
                <div className="segmented-control">
                  <button
                    type="button"
                    className={`segment-option ${alignmentMode === 'ToC-Based' ? 'active' : ''}`}
                    onClick={() => setAlignmentMode('ToC-Based')}
                  >
                    ToC-Based
                  </button>
                  <button
                    type="button"
                    className={`segment-option ${alignmentMode === 'Full Document' ? 'active' : ''}`}
                    onClick={() => setAlignmentMode('Full Document')}
                  >
                    Full Document
                  </button>
                </div>
              </div>
              
              {alignmentMode === 'ToC-Based' && (
                <div className="form-group toc-group">
                  <label htmlFor="tocPageNum">ToC Page Number</label>
                  <input
                    id="tocPageNum"
                    type="number"
                    value={tocPageNum}
                    onChange={(e) => setTocPageNum(parseInt(e.target.value, 10))}
                    min="1"
                    step="1"
                  />
                </div>
              )}
            </div>
          </div>

          <div className="panel-section run-section">
            <h2 className="panel-header">
              <FiZap /> 3. Execute
            </h2>
            <div className="run-buttons">
              <button
                type="submit"
                className="btn btn-primary"
                disabled={isLoading || !englishFile || !germanFile}
              >
                {isLoading ? (
                  <RingLoader size={20} color={"#fff"} speedMultiplier={1} />
                ) : (
                  'Run Analysis'
                )}
                {isLoading && <span>Analyzing...</span>}
              </button>
              
              {reportBase64 && !isLoading && (
                <button type="button" onClick={handleDownload} className="btn btn-secondary">
                  <FiDownload />
                  <span>Download Report</span>
                </button>
              )}
            </div>
          </div>
        </form>

        {/* --- Results Panel --- */}
        <section className="results-panel">
          <h2 className="panel-header">Evaluation Results</h2>
          <div className="results-content glass-panel">
            <StatusDisplay
              isLoading={isLoading}
              error={error}
              findingsCount={findings.length}
              analysisComplete={analysisComplete} 
            />
            
            {findings.length > 0 && !isLoading && (
              <div className="findings-list">
                {findings.map((finding, index) => (
                  <FindingCard key={index} finding={finding} />
                ))}
              </div>
            )}
          </div>
        </section>
      </main>
    </div>
  );
}

// --- Helper Component: FileUploadZone ---
// (Unchanged)
function FileUploadZone({ file, setFile, title }) {
  const [isDragging, setIsDragging] = useState(false);
  const inputId = `file-input-${title.replace(' ', '-')}`;

  const handleDragOver = (e) => { e.preventDefault(); setIsDragging(true); };
  const handleDragLeave = (e) => { e.preventDefault(); setIsDragging(false); };
  const handleDrop = (e) => {
    e.preventDefault();
    setIsDragging(false);
    const droppedFile = e.dataTransfer.files[0];
    if (droppedFile && droppedFile.type === "application/pdf") setFile(droppedFile);
  };
  const handleFileChange = (e) => {
    const selectedFile = e.target.files[0];
    if (selectedFile) setFile(selectedFile);
  };

  if (file) {
    return (
      <div className="file-drop-zone file-selected">
        <FiFileText className="file-icon" />
        <span className="file-name">{file.name}</span>
        <button type="button" className="remove-file-btn" onClick={() => setFile(null)}>
          <FiX />
        </button>
      </div>
    );
  }
  return (
    <label
      htmlFor={inputId}
      className={`file-drop-zone ${isDragging ? 'dragging' : ''}`}
      onDragOver={handleDragOver} onDragLeave={handleDragLeave} onDrop={handleDrop}
    >
      <input type="file" id={inputId} accept="application/pdf" onChange={handleFileChange} className="hidden-file-input" />
      <FiUploadCloud className="upload-icon" />
      <span className="upload-title">{title}</span>
      <span className="upload-text">Drag & drop PDF, or click to browse</span>
    </label>
  );
}

// --- Helper Component: StatusDisplay ---
// (This is the simplified version without the cycling status text)
function StatusDisplay({ isLoading, error, findingsCount, analysisComplete }) {
  if (isLoading) {
    return (
      <div className="status-display loading">
        <RingLoader color={"#8884d8"} size={60} />
        <h3>Analyzing Documents...</h3>
        <p className="loading-status-text">This may take several minutes. Please wait.</p>
      </div>
    );
  }

  if (error) {
    return (
      <div className="status-display error">
        <FiAlertTriangle className="status-icon" />
        <h3>Analysis Failed</h3>
        <p>{error}</p>
      </div>
    );
  }

  if (analysisComplete && findingsCount === 0) {
    return (
      <div className="status-display success"> 
        <FiCheckCircle className="status-icon" />
        <h3>Analysis Complete</h3>
        <p>No significant issues found. Good to go!</p>
      </div>
    );
  }

  if (!analysisComplete && findingsCount === 0) { 
    return (
      <div className="status-display empty">
        <FiCheckCircle className="status-icon" />
        <h3>Ready to Analyze</h3>
        <p>Upload your documents and click "Run Analysis" to see the results.</p>
      </div>
    );
  }

  return null;
}

// --- Helper Component: FindingCard ---
// (Unchanged)
function FindingCard({ finding }) {
  const {
    page, type, suggestion, english_text, german_text, original_phrase, translated_phrase,
  } = finding;
  
  const typeClass = type.toLowerCase().replace(' ', '-');

  return (
    <div className="finding-card glass-panel">
      <div className="card-header">
        <span className={`card-badge ${typeClass}`}>{type}</span>
        <span className="card-page">Page: {page || 'N/A'}</span>
      </div>

      {(original_phrase || translated_phrase) && (
        <div className="card-section focus-section">
          <h4>Key Discrepancy</h4>
          <div className="text-pair">
            <div className="text-block">
              <strong>English Phrase</strong>
              <p className="highlight-en">{original_phrase || 'N/A'}</p>
            </div>
            <div className="text-block">
              <strong>German Phrase</strong>
              <p className="highlight-de">{translated_phrase || 'N/A'}</p>
            </div>
          </div>
        </div>
      )}

      <div className="card-section context-section">
        <h4>Full Context</h4>
        <div className="text-pair">
          <div className="text-block">
            <strong>English Text</strong>
            <blockquote>{english_text}</blockquote>
          </div>
          <div className="text-block">
            <strong>German Text</strong>
            <blockquote>{german_text}</blockquote>
          </div>
        </div>
      </div>

      <div className="card-section suggestion-section">
        <strong><FiZap /> Suggestion:</strong>
        <p>{suggestion}</p>
      </div>
    </div>
  );
}

export default App;

// frontend/src/index.css


// frontend/src/main.jsx
import { StrictMode } from 'react'
import { createRoot } from 'react-dom/client'
import './index.css'
import App from './App.jsx'

createRoot(document.getElementById('root')).render(
  <StrictMode>
    <App />
  </StrictMode>,
)

// frontend/index.html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>frontend</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>

// frontend/package.json
{
  "name": "frontend",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "axios": "^1.13.2",
    "react": "^19.2.0",
    "react-dom": "^19.2.0",
    "react-icons": "^5.5.0",
    "react-spinners": "^0.17.0"
  },
  "devDependencies": {
    "@eslint/js": "^9.39.1",
    "@types/react": "^19.2.2",
    "@types/react-dom": "^19.2.2",
    "@vitejs/plugin-react": "^5.1.0",
    "eslint": "^9.39.1",
    "eslint-plugin-react-hooks": "^5.2.0",
    "eslint-plugin-react-refresh": "^0.4.24",
    "globals": "^16.5.0",
    "vite": "^7.2.2"
  }
}

// frontend/README.md
# React + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) (or [oxc](https://oxc.rs) when used in [rolldown-vite](https://vite.dev/guide/rolldown)) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh

## React Compiler

The React Compiler is not enabled on this template because of its impact on dev & build performances. To add it, see [this documentation](https://react.dev/learn/react-compiler/installation).

## Expanding the ESLint configuration

If you are developing a production application, we recommend using TypeScript with type-aware lint rules enabled. Check out the [TS template](https://github.com/vitejs/vite/tree/main/packages/create-vite/template-react-ts) for information on how to integrate TypeScript and [`typescript-eslint`](https://typescript-eslint.io) in your project.

